{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "419011ab-dc9f-4746-a7fc-f1a34d4f3f1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f28ef18b-0d54-455d-9696-1f651f88b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import copy, deepcopy\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"\"\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624b8cb9-af89-4de0-895d-7569647ced53",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bdebfc3-f398-4b61-b77d-9c309f2aa6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEW_SHOT_EXAMPLES_ENTS = \"\"\"\n",
    "                  EXAMPLE#1\n",
    "                   QUESTION: What does DiCaprio's full name sound like?\n",
    "                   CANDIDATE ENTITIES: \n",
    "                   Q116673393: Sibon irmelindicaprioae -- species of snake\n",
    "                    Q38111: Leonardo DiCaprio -- American actor and film producer (born 1974)\n",
    "                    Q11461: sound -- vibration that propagates as an acoustic wave\n",
    "                    Q36860035: DiCaprio -- family name\n",
    "                    Q25349951: Martin Scorsese and Leonardo DiCaprio -- collaborations\n",
    "                    Q56653813: DiCaprio 2 -- album by J.I.D\n",
    "                   RELEVANT ENTITIES: Q38111.\n",
    "                   \n",
    "                   \n",
    "                   EXAMPLE#2\n",
    "                   QUESTION: In which city near Moscow is the new Jerusalem monastery located?\n",
    "                    CANDIDATE ENTITIES: \n",
    "                    Q55502: Kingdom of Jerusalem -- medieval Christian kingdom in the Middle East\n",
    "                    Q773979: New Jerusalem Monastery -- monastery in Moscow Oblast, Russia\n",
    "                    Q1218: Jerusalem -- city in the Middle East, holy to the three Abrahamic religions\n",
    "                    Q649: Moscow -- capital and most populous city of Russia\n",
    "                    Q515: city -- large human settlement\n",
    "                    Q13164: Moscow State University -- university in Moscow, Russia\n",
    "                    Q6760: UTC+03:00 -- identifier for a time offset from UTC of +3\n",
    "                    Q10540001: Jerusalem -- family name                    \n",
    "                    RELEVANT ENTITIES: Q773979, Q649.\n",
    "\n",
    "                    \n",
    "                    EXAMPLE#3\n",
    "                    QUESTION: What capital stands on the banks of Potalaka?\n",
    "                    CANDIDATE ENTITIES: \n",
    "                    Q11626848: Mount Potalaka -- the mythical dwelling of the Buddhist bodhisattva Avalokiteśvara, said to exist in India\n",
    "                    Q22687: bank -- financial institution that accepts deposits\n",
    "                    Q60756888: Potalaka Guanyin -- sculpture by unknown artist (1965.556)\n",
    "                    Q179444: Potomac River -- river in the mid-Atlantic United States\n",
    "                    Q193893: capital -- upper part of a column (architecture)\n",
    "                    Q60: New York City -- most populous city in the United States\n",
    "                    Q5119: capital city -- primary governing city of a top-level (country) or first-level and second-level subdivision (country, state, province, regency, etc) political entity\n",
    "                    **Reasoning:**  \n",
    "                    - \"Capital\" refers to a **governing city**, not architectural elements (Q193893).  \n",
    "                    - \"Potalaka\" (Q11626848) is a **mythical** location, so no real-world capital is directly linked.  \n",
    "                    - Since no entity directly matches the question, **the most general applicable concept** is \"capital city\" (Q5119).\n",
    "                    RELEVANT ENTITIES: Q179444, Q5119.\n",
    "                    \n",
    "                    \n",
    "                    EXAMPLE#4 \n",
    "                    QUESTION: What is the official language of Brazil?  \n",
    "                    CANDIDATE ENTITIES:  \n",
    "                    Q750553: Spanish language -- Romance language originating in Spain  \n",
    "                    Q5146: Portuguese language -- Romance language, official in Portugal and Brazil  \n",
    "                    Q155: Brazil -- country in South America  \n",
    "                    Q483110: Brasília -- capital city of Brazil\n",
    "                    **Reasoning**:  \n",
    "                    - \"Official language\" refers to the main language used for governance.  \n",
    "                    - The description of Q5146 explicitly states it is official in Brazil.  \n",
    "                    - Q750553 (Spanish) is incorrect because it is **not** the official language.  \n",
    "                    - Q155 and Q483110 are related but not **languages**. \n",
    "                    RELEVANT ENTITIES: Q5146.  \n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT_ENTS = f\"\"\"You are an experienced WikiData user. \n",
    "                   You receive a QUESTION and a SET of extracted Wikidata CANDIDATE ENTITIES, retrieved from an index based on similarity between the QUESTION and the ENTITY. \n",
    "                   Each entity has a wikidata ID, label and description in a form of Wikidata ID: label -- description. \n",
    "                   Your task is to select only the most semantically relevant entities based on their labels and descriptions.\n",
    "                   \n",
    "                   Instruction:\n",
    "                    -- Ignore entities that are loosely related, homonyms, or have indirect contextual links to the QUESTION.\n",
    "                    -- If no entity perfectly matches the question, select the best available entity based on contextual closeness.\n",
    "                    -- If multiple entities seem relevant, prefer those with a stronger direct connection to the query subject.\n",
    "                    -- If there are ambiguous entities that relate to the different countries, ALWAYS choose the entity that is related to Russia, based on description.\n",
    "                    -- Some questions may have multiple correct entities. Return all entities that are directly relevant. Do NOT include entities that are only indirectly related (e.g., broad categories like 'city' instead of a specific location).\n",
    "                    -- DO NOT reject entity, if it fits to the entity mentioned in query, but DOES NOT DIRECTLY answer the question.\n",
    "                    -- Always include reasoning in the beginning of the responce.\n",
    "                    -- Always place \"RELEVANT ENTITIES: ...\" at the end of your response.\n",
    "\n",
    "                   Here are examples:\n",
    "                   {FEW_SHOT_EXAMPLES_ENTS}\n",
    "                   \"\"\"\n",
    "\n",
    "USER_PROMPT_ENTS = \"\"\"QUESTION: {question}\\nCANDIDATE ENTITIES:\\n{candidate_list_str}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69c29b6e-84b7-451a-ad2b-95c5c1acced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEW_SHOT_EXAMPLES_PROP = \"\"\"\n",
    "                    EXAMPLE#1\n",
    "                    QUESTION: How much does Nurmagomedov weigh?\n",
    "                    CANDIDATE PROPERTIES:\n",
    "                    P166: award received -- award or recognition received by a person, organization or creative work\n",
    "                    P54: member of sports team -- sports teams or clubs that the subject represents or represented\n",
    "                    P1082: population -- number of people inhabiting the place; number of people of subject\n",
    "                    P1351: number of points/goals/set scored -- goals / points scored in a match or an event used as qualifier to the participant. Use P1358 for league points.\n",
    "                    P1350: number of matches played/races/starts -- matches or games a player or a team played during an event. Also a total number of matches a player officially appeared in during the whole career.\n",
    "                    P2121: prize money -- amount in a specific currency\n",
    "                    P585: point in time -- date something took place, existed or a statement was true; for providing time use the \"refine date\" property (P4241)\n",
    "                    P2067: mass -- mass (in colloquial usage also known as weight) of the item\n",
    "                    P1412: languages spoken, written or signed -- language(s) that a person or a people speaks, writes or signs, including the native language(s)\n",
    "                    P2046: area -- area occupied by an object\n",
    "                    RELEVANT PROPERTIES: P2067\n",
    "\n",
    "\n",
    "                    EXAMPLE#2\n",
    "                    QUESTION: Where is the Academy of Sciences of Armenia located\n",
    "                    CANDIDATE PROPERTIES:\n",
    "                    P463: member of -- organization, club or musical group to which the subject belongs. Do not use for membership in ethnic or social groups, nor for holding a political position, such as a member of parliament (use P39 for that)\n",
    "                    P31: instance of -- that class of which this subject is a particular example and member; different from P279 (subclass of); for example: K2 is an instance of mountain; volcano is a subclass of mountain (and an instance of volcanic landform)\n",
    "                    P19: place of birth -- most specific known birth location of a person, animal or fictional character\n",
    "                    P580: start time -- time an entity begins to exist or a statement starts being valid\n",
    "                    P582: end time -- moment when an entity ceases to exist or a statement stops being valid\n",
    "                    P69: educated at -- educational institution attended by subject\n",
    "                    P159: headquarters location -- city or town where an organization's headquarters is or has been situated. Use P276 qualifier for specific building\n",
    "                    P585: point in time -- date something took place, existed or a statement was true; for providing time use the \"refine date\" property (P4241)\n",
    "                    RELEVANT PROPERTIES: P159\n",
    "\n",
    "\n",
    "                    EXAMPLE#3\n",
    "                    QUESTION: What is the singing voice of Dmitri Hvorostovsky?\n",
    "                    CANDIDATE PROPERTIES:\n",
    "                    P412: voice type -- person's voice type. expected values: soprano, mezzo-soprano, contralto, countertenor, tenor, baritone, bass (and derivatives)\n",
    "                    P725: voice actor -- performer of a spoken role in a creative work such as animation, video game, radio drama, or dubbing over [use \"character role\" (P453) as qualifier] [use \"cast member\" (P161) for live acting]\n",
    "                    P175: performer -- actor, musician, band or other performer associated with this role or musical work\n",
    "                    P453: character role -- specific role played or filled by subject -- use only as qualifier of \"cast member\" (P161), \"voice actor\" (P725)\n",
    "                    P179: part of the series -- series which contains the subject\n",
    "                    P674: characters -- characters which appear in this item (like plays, operas, operettas, books, comics, films, TV series, video games)\n",
    "                    P1441: present in work -- this (fictional or fictionalized) entity, place, or person appears in that work as part of the narration (use P2860 for works citing other works, P361/P1433 for works being part of other works, P1343 for entities described in non-fictional accounts)\n",
    "                    **Reasoning:** \n",
    "                    - the question asks about voice's characteristics of some person\n",
    "                    - P412 is relevant, because it's a property described a voice type, which is voice's characteristic\n",
    "                    - P725, P175, P674 represent properties described a person role in something, not related to voice\n",
    "                    - other properties also represent something not similar to voice \n",
    "                    RELEVANT PROPERTIES: P412\n",
    "                   \n",
    "                   \n",
    "                    EXAMPLE#4\n",
    "                    QUESTION: Who was S. V. Mikhalkov's co-author in writing the text of the anthem of the Soviet Union?\n",
    "                    CANDIDATE PROPERTIES:\n",
    "                    P31: instance of -- that class of which this subject is a particular example and member; different from P279 (subclass of); for example: K2 is an instance of mountain; volcano is a subclass of mountain (and an instance of volcanic landform)\n",
    "                    P86: composer -- person(s) who wrote the music [for lyricist, use \"lyrics by\" (P676)]\n",
    "                    P1412: languages spoken, written or signed -- language(s) that a person or a people speaks, writes or signs, including the native language(s)\n",
    "                    P92: main regulatory text -- text setting the main rules by which the subject is regulated\n",
    "                    P50: author -- main creator(s) of a written work (use on works, not humans); use P2093 (author name string) when Wikidata item is unknown or does not exist\n",
    "                    P155: follows -- immediately prior item in a series of which the subject is a part, preferably use as qualifier of P179 [if the subject has replaced the preceding item, e.g. political offices, use \"replaces\" (P1365)]\n",
    "                    P676: lyricist -- author of song lyrics\n",
    "                    **Reasoning:** \n",
    "                    - the question asks about an co-author of a some national anthem's text, not the music itself!\n",
    "                    - description of P676 makes it clear that it represent \"author of song lyrics\" - that's what we needed\n",
    "                    - P31's description is too general and not correspond to songs's author\n",
    "                    - P86, P50 are close, but they describe a composer/author of written work, not a lyrics writer\n",
    "                    - other properties also describe something another than lyric's writer\n",
    "                    RELEVANT PROPERTIES: P676\n",
    "\n",
    "\n",
    "                    EXAMPLE#5\n",
    "                    QUESTION: In which country did the great Russian chess player Alexander Alekhine end his life?\n",
    "                    CANDIDATE PROPERTIES:\n",
    "                    P20: place of death -- most specific known (e.g. city instead of country, or hospital instead of city) death location of a person, animal or fictional character\n",
    "                    P27: country of citizenship -- the object is a country that recognizes the subject as its citizen\n",
    "                    P582: end time -- moment when an entity ceases to exist or a statement stops being valid\n",
    "                    P31: instance of -- that class of which this subject is a particular example and member; different from P279 (subclass of); for example: K2 is an instance of mountain; volcano is a subclass of mountain (and an instance of volcanic landform)\n",
    "                    P276: location -- location of the object, structure or event. In the case of an administrative entity as containing item use P131. For statistical entities use P8138. In the case of a geographic entity use P706. Use P7153 for locations associated with the object\n",
    "                    P26: spouse -- the subject has the object as their spouse (husband, wife, partner, etc.). Use \"unmarried partner\" (P451) for non-married companions\n",
    "                    P17: country -- sovereign state that this item is in (not to be used for human beings)\n",
    "                    P39: position held -- subject currently or formerly holds the object position or public office\n",
    "                    P580: start time -- time an entity begins to exist or a statement starts being valid\n",
    "                    P19: place of birth -- most specific known birth location of a person, animal or fictional character\n",
    "                    **Reasoning:**\n",
    "                    - the question asks about location of somebody's death and it's country where it happened\n",
    "                    - in the candidates we can clearly see P20 and P17, which respresent **place of death** and **contry**\n",
    "                    - P276 and P582 are close, but too common for this QUESTION\n",
    "                    - other has no relation to QUESTION's PROPERTIES\n",
    "                    RELEVANT PROPERTIES: P20, P17\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT_PROP = f\"\"\"You are an experienced WikiData user. \n",
    "                   You receive a QUESTION and a SET of extracted Wikidata CANDIDATE PROPERTIES, retrieved from an index based on similarity between the QUESTION and the PROPERTY. \n",
    "                   Each property has a wikidata ID, label and description in a form of Wikidata ID: label -- description. \n",
    "                   Your task is to select only the most semantically relevant properties based on their labels and descriptions.\n",
    "                   \n",
    "                   Instruction:\n",
    "                    -- Ignore properties that are loosely related, homonyms, or have indirect contextual links to the QUESTION.\n",
    "                    -- If no property perfectly matches the question, select the best available property based on contextual closeness.\n",
    "                    -- If multiple properties seem relevant, prefer those with a stronger direct connection to the query subject.\n",
    "                    -- Some questions may have multiple correct properties. Return all properties that are directly relevant. \n",
    "                    -- Always include reasoning in the beginning of the responce.\n",
    "                    -- Always place \"RELEVANT PROPERTIES: ...\" at the end of your response.\n",
    "\n",
    "                   Here are examples:\n",
    "                   {FEW_SHOT_EXAMPLES_PROP}\n",
    "                   \"\"\"\n",
    "\n",
    "USER_PROMPT_PROP = \"\"\"QUESTION: {question}\\nCANDIDATE PROPERTIES:\\n{candidate_list_str}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f0c7d7-dada-4812-864e-b75722c7f9bc",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d43fd709-f5a3-4761-8105-0a65da37d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Prompt and Preprocessing Functions\n",
    "'''\n",
    "\n",
    "def get_default(dic, field, default=''):\n",
    "    return dic[field] if field in dic else default\n",
    "\n",
    "    \n",
    "def prepare_candidates(sample, retriever_output):    \n",
    "    sample_id = sample['uid']\n",
    "    # relevant_ids = list(sample['id2alias'].keys())\n",
    "    retrived_cands = retriever_output[str(sample_id)]\n",
    "    retrived_ids = retrived_cands.keys()\n",
    "    retrived_ids = list(filter(lambda x: x is not None, retrived_ids))\n",
    "    \n",
    "    candidates_set = list(set(retrived_ids\n",
    "                              # + relevant_ids\n",
    "                             ))\n",
    "    # HERE I DO SHUFFLING, SINCE I DO NOT KNOW THE ORDER FROM RETRIEVER\n",
    "    random.shuffle(candidates_set)\n",
    "    \n",
    "    entities_list = [f\"{key}: {get_default(retrived_cands[key], 'label')} -- {get_default(retrived_cands[key], 'description')}\" for key in retrived_ids]\n",
    "    entities_str = \"\\n\".join(entities_list)\n",
    "    return entities_str\n",
    "        \n",
    "\n",
    "def construct_user_prompt(sample, retriever_output, user_prompt):\n",
    "    question = sample['question_eng']\n",
    "    candidates_set_string = prepare_candidates(sample, retriever_output)\n",
    "    user_prompt = user_prompt.format(question=question, candidate_list_str=candidates_set_string)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bdc40b0-ec37-45c3-b0f6-78b3f0c5a840",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Run OpenAI Functions\n",
    "'''\n",
    "def run_sample_with_openai(sample, retriever_output, system_prompt, user_prompt):\n",
    "    user_prompt = construct_user_prompt(sample, retriever_output, user_prompt)\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0,   # Reduce randomness for consistent entity selection\n",
    "        max_tokens=400,  # Adjust if the response is cut off\n",
    "        top_p=1,         # Avoid sampling randomness\n",
    "        frequency_penalty=0,  \n",
    "        presence_penalty=0  \n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eabae1f6-e71c-42c7-afc6-830f59fe3b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Eval Functions\n",
    "'''\n",
    "def extract_wikidata_ids(text, search_pattern):\n",
    "    pattern = search_pattern + r\" ([\\w, ]+)\"\n",
    "    \n",
    "    match = re.search(pattern, text)\n",
    "    \n",
    "    if match:\n",
    "        # Extract the IDs and return them as a list\n",
    "        wikidata_ids = match.group(1).split(', ')\n",
    "        return wikidata_ids\n",
    "    else:\n",
    "        return []\n",
    "        \n",
    "# RELEVANT ENTITIES: / RELEVANT PROPERTIES:\n",
    "def parse_responce(responce_str, search_pattern):\n",
    "    if search_pattern == 'entity':\n",
    "        search_pattern = 'RELEVANT ENTITIES:'\n",
    "    elif search_pattern == 'property':\n",
    "        search_pattern = 'RELEVANT PROPERTIES:'\n",
    "    else:\n",
    "        raise Exception('Choose correct seacrh pattern')\n",
    "    \n",
    "    # parse main case\n",
    "    if search_pattern in responce_str:\n",
    "        wikidata_ids = extract_wikidata_ids(responce_str, search_pattern)\n",
    "        return wikidata_ids\n",
    "    # I hope there are no other cases, but still -- better to ch\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_metrics(eval_data, response_data, search_pattern):\n",
    "\n",
    "    if search_pattern == 'entity':\n",
    "        get_gold = lambda x: list(x['id2alias'].keys())\n",
    "    elif search_pattern == 'property':\n",
    "        get_gold = lambda x: [y.split(':')[-1] for y in x['question_props']]\n",
    "    else:\n",
    "        raise Exception('Choose correct seacrh pattern')\n",
    "    \n",
    "    overall_precision, overall_recall, overall_f1 = 0, 0, 0\n",
    "    failed_examples = []\n",
    "    error_generations, incomplete_generation = [], []\n",
    "    false_positive_generations = []\n",
    "    for idx, pair in enumerate(zip(eval_data, response_data)):\n",
    "        sample, gpt_response = pair\n",
    "        extracted_candidates = parse_responce(gpt_response, search_pattern)\n",
    "        \n",
    "        gold_ids = get_gold(sample)\n",
    "\n",
    "        \n",
    "        if extracted_candidates:\n",
    "            true_positives = set(extracted_candidates) & set(gold_ids)\n",
    "    \n",
    "            precision = len(true_positives) / len(extracted_candidates) if extracted_candidates else 0.0\n",
    "            if precision == 0:\n",
    "                false_positive_generations.append([idx, gpt_response, gold_ids])\n",
    "    \n",
    "            # Recall: Proportion of gold entities that are correctly predicted\n",
    "            recall = len(true_positives) / len(gold_ids) if gold_ids else 0.0\n",
    "            if recall == 0:\n",
    "                error_generations.append([idx, gpt_response, gold_ids])\n",
    "            if recall != 1:\n",
    "                incomplete_generation.append([idx, gpt_response, gold_ids])\n",
    "    \n",
    "            # F1-Score: Harmonic mean of Precision and Recall\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0.0\n",
    "    \n",
    "            overall_precision += precision\n",
    "            overall_recall += recall\n",
    "            overall_f1 += f1\n",
    "        else:\n",
    "            failed_examples.append(gpt_response)\n",
    "        \n",
    "    overall_precision /= len(response_data)\n",
    "    overall_recall /= len(response_data)\n",
    "    overall_f1 /= len(response_data)\n",
    "    \n",
    "    print('Precision: ', overall_precision)\n",
    "    print('Recall: ', overall_recall)\n",
    "    print('F1: ', overall_f1)\n",
    "\n",
    "\n",
    "def get_result(data, retriver_output, response_arr, search_pattern):\n",
    "    result = {}\n",
    "    for idx, pair in enumerate(zip(data, response_arr)):\n",
    "        sample, gpt_response = pair\n",
    "        extracted_candidates = parse_responce(gpt_response, search_pattern)\n",
    "        uid = str(sample['uid'])\n",
    "        result[uid] = {\n",
    "            'question_eng': sample['question_eng'],\n",
    "            'query': sample['query'],\n",
    "            'candidates': {cand: retriver_output[uid][cand]['label']\n",
    "                           for cand in extracted_candidates if cand in retriver_output[uid]} if extracted_candidates else {}\n",
    "        }\n",
    "    return result\n",
    "\n",
    "    \n",
    "\n",
    "'''\n",
    "Test Functions\n",
    "'''\n",
    "def test_prompt(data, retriever_output, user_prompt, idx):\n",
    "    sample = data[idx]\n",
    "    print('SPARQL: ', sample['query'])\n",
    "    print()\n",
    "    result_user_prompt = construct_user_prompt(sample, retriever_output, user_prompt)\n",
    "    print(result_user_prompt[:])\n",
    "\n",
    "\n",
    "def test_openai(data, retriver_output, system_prompt, user_prompt, idx):\n",
    "    sample = data[idx]\n",
    "    print('QUESTION: ', sample['question_eng'])\n",
    "    print('SPARQL: ', sample['query'])\n",
    "    \n",
    "    openai_responce = run_sample_with_openai(sample, retriver_output, system_prompt, user_prompt)\n",
    "    print()\n",
    "    print(openai_responce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9769bf00-739d-4acc-9d38-8f4859c73b84",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Run Entitties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ae502359-e391-494b-af71-588422247037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419 391\n",
      "retr 100: 0.7519181585677749\n",
      "retr 10 : 0.6061381074168798\n"
     ]
    }
   ],
   "source": [
    "rubq_train = json.load(open(\"data/train_with_aliases.json\"))\n",
    "rubq_test = json.load(open(\"data/test_with_aliases.json\"))\n",
    "\n",
    "rubq_retr_100_ent = json.load(open('data/datasets/rubq_test_entities_retrieval.json'))\n",
    "rubq_retr_10_ent = {k: dict(list(v.items())[:10]) for k, v in rubq_retr_100_ent.items()}\n",
    "\n",
    "rubq_test_eval = [sample for sample in rubq_test if str(sample['uid']) in rubq_retr_100_ent]\n",
    "\n",
    "print(len(rubq_test), len(rubq_test_eval))\n",
    "\n",
    "print(\n",
    "    f'retr 100: {np.mean([len(set(x['id2alias'].keys()) & set(rubq_retr_100_ent[str(x['uid'])])) > 0 for x in rubq_test_eval])}',\n",
    "    f'retr 10 : {np.mean([len(set(x['id2alias'].keys()) & set(rubq_retr_10_ent[str(x['uid'])])) > 0 for x in rubq_test_eval])}',\n",
    "    sep='\\n'\n",
    ")\n",
    "\n",
    "eval_data = deepcopy(rubq_test_eval)\n",
    "eval_retriver = deepcopy(rubq_retr_10_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "24270dc2-2355-4c18-a3e3-ba5439cae70a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPARQL:  SELECT ?answer \n",
      "WHERE {\n",
      "  wd:Q14452 wdt:P17 ?answer\n",
      "}\n",
      "\n",
      "QUESTION: Which country does the famous Easter island belong to?\n",
      "CANDIDATE ENTITIES:\n",
      "Q21562419: Ecological release and venom evolution of a predatory marine snail at Easter Island -- scientific article\n",
      "Q67704577: PROTESTANT EASTER SERVICES, MINDORO ISLAND, PHILIPPINE ISLANDS ; 40TH DIVISION LANDS ON NEGROS ISLAND, PHIIPPINE ISLANDS ; ROOSEVELT MEMORIAL SERVICES, PARIS, FRANCE (NAID 17838) -- item in the National Archives and Records Administration's holdings\n",
      "Q115116609: Easter Island -- special territory of Chile\n",
      "Q61468799: Morphology and distribution of seamounts surrounding Easter Island -- scientific article\n",
      "Q14452: Easter Island -- Polynesian island and special territory of Chile\n",
      "Q47230709: DNA from ancient Easter Islanders -- scientific article published in May 1994\n",
      "Q30856142: Climate windows for Polynesian voyaging to New Zealand and Easter Island. -- scientific article\n",
      "Q40774733: A serological survey of sera from domestic animals on Easter Island -- scientific article\n",
      "Q70454899: Survey of Easter Island Soils for Keratinophilic Fungi -- scientific article published on 01 January 1972\n",
      "Q36911840: A serological study of Cytomegalovirus infection in the population of Easter Island -- scientific article published on January 1969\n"
     ]
    }
   ],
   "source": [
    "test_prompt(eval_data, eval_retriver, USER_PROMPT_ENTS, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b07c9299-69e4-485f-a974-29edcdbfd7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:  Which country does the famous Easter island belong to?\n",
      "SPARQL:  SELECT ?answer \n",
      "WHERE {\n",
      "  wd:Q14452 wdt:P17 ?answer\n",
      "}\n",
      "\n",
      "**Reasoning**:  \n",
      "- The question asks for the country to which Easter Island belongs.  \n",
      "- Q115116609 and Q14452 both refer to Easter Island as a special territory of Chile, which directly answers the question.  \n",
      "- The other entities are scientific articles related to Easter Island but do not provide information about the country it belongs to.\n",
      "\n",
      "RELEVANT ENTITIES: Q115116609, Q14452.\n"
     ]
    }
   ],
   "source": [
    "test_openai(eval_data, eval_retriver, SYSTEM_PROMPT_ENTS, USER_PROMPT_ENTS, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46598869-20ff-4836-b8fe-86ea75ad48fc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████████▋                        | 159/391 [11:38<16:58,  4.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\n",
      "Перезапустите VPN и запустите ячейку\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRateLimitError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 20\u001B[0m\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;28mprint\u001B[39m(i)\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mПерезапустите VPN и запустите ячейку\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 20\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(responce_list) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(eval_data)\n",
      "Cell \u001B[0;32mIn[11], line 15\u001B[0m\n\u001B[1;32m     12\u001B[0m             \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m     14\u001B[0m         sample \u001B[38;5;241m=\u001B[39m eval_data[i]\n\u001B[0;32m---> 15\u001B[0m         result \u001B[38;5;241m=\u001B[39m run_sample_with_openai(sample, eval_retriver, SYSTEM_PROMPT_ENTS, USER_PROMPT_ENTS)\n\u001B[1;32m     16\u001B[0m         responce_list\u001B[38;5;241m.\u001B[39mappend(result)\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "Cell \u001B[0;32mIn[5], line 7\u001B[0m, in \u001B[0;36mrun_sample_with_openai\u001B[0;34m(sample, retriever_output, system_prompt, user_prompt)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_sample_with_openai\u001B[39m(sample, retriever_output, system_prompt, user_prompt):\n\u001B[1;32m      5\u001B[0m     user_prompt \u001B[38;5;241m=\u001B[39m construct_user_prompt(sample, retriever_output, user_prompt)\n\u001B[0;32m----> 7\u001B[0m     response \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mchat\u001B[38;5;241m.\u001B[39mcompletions\u001B[38;5;241m.\u001B[39mcreate(\n\u001B[1;32m      8\u001B[0m         model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-4-1106-preview\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      9\u001B[0m         messages\u001B[38;5;241m=\u001B[39m[\n\u001B[1;32m     10\u001B[0m             {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msystem\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: system_prompt},\n\u001B[1;32m     11\u001B[0m             {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: user_prompt}\n\u001B[1;32m     12\u001B[0m         ],\n\u001B[1;32m     13\u001B[0m         temperature\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,   \u001B[38;5;66;03m# Reduce randomness for consistent entity selection\u001B[39;00m\n\u001B[1;32m     14\u001B[0m         max_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m400\u001B[39m,  \u001B[38;5;66;03m# Adjust if the response is cut off\u001B[39;00m\n\u001B[1;32m     15\u001B[0m         top_p\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,         \u001B[38;5;66;03m# Avoid sampling randomness\u001B[39;00m\n\u001B[1;32m     16\u001B[0m         frequency_penalty\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,  \n\u001B[1;32m     17\u001B[0m         presence_penalty\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m  \n\u001B[1;32m     18\u001B[0m     )\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m response\u001B[38;5;241m.\u001B[39mchoices[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mmessage\u001B[38;5;241m.\u001B[39mcontent\n",
      "File \u001B[0;32m/opt/miniconda3/envs/env_chatgptapi/lib/python3.13/site-packages/openai/_utils/_utils.py:279\u001B[0m, in \u001B[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    277\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    278\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[0;32m--> 279\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/env_chatgptapi/lib/python3.13/site-packages/openai/resources/chat/completions.py:850\u001B[0m, in \u001B[0;36mCompletions.create\u001B[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    808\u001B[0m \u001B[38;5;129m@required_args\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    809\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m    810\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    847\u001B[0m     timeout: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m|\u001B[39m httpx\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m|\u001B[39m NotGiven \u001B[38;5;241m=\u001B[39m NOT_GIVEN,\n\u001B[1;32m    848\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatCompletion \u001B[38;5;241m|\u001B[39m Stream[ChatCompletionChunk]:\n\u001B[1;32m    849\u001B[0m     validate_response_format(response_format)\n\u001B[0;32m--> 850\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post(\n\u001B[1;32m    851\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/chat/completions\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    852\u001B[0m         body\u001B[38;5;241m=\u001B[39mmaybe_transform(\n\u001B[1;32m    853\u001B[0m             {\n\u001B[1;32m    854\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: messages,\n\u001B[1;32m    855\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m: model,\n\u001B[1;32m    856\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maudio\u001B[39m\u001B[38;5;124m\"\u001B[39m: audio,\n\u001B[1;32m    857\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrequency_penalty\u001B[39m\u001B[38;5;124m\"\u001B[39m: frequency_penalty,\n\u001B[1;32m    858\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunction_call\u001B[39m\u001B[38;5;124m\"\u001B[39m: function_call,\n\u001B[1;32m    859\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunctions\u001B[39m\u001B[38;5;124m\"\u001B[39m: functions,\n\u001B[1;32m    860\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogit_bias\u001B[39m\u001B[38;5;124m\"\u001B[39m: logit_bias,\n\u001B[1;32m    861\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogprobs\u001B[39m\u001B[38;5;124m\"\u001B[39m: logprobs,\n\u001B[1;32m    862\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_completion_tokens\u001B[39m\u001B[38;5;124m\"\u001B[39m: max_completion_tokens,\n\u001B[1;32m    863\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_tokens\u001B[39m\u001B[38;5;124m\"\u001B[39m: max_tokens,\n\u001B[1;32m    864\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: metadata,\n\u001B[1;32m    865\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodalities\u001B[39m\u001B[38;5;124m\"\u001B[39m: modalities,\n\u001B[1;32m    866\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn\u001B[39m\u001B[38;5;124m\"\u001B[39m: n,\n\u001B[1;32m    867\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparallel_tool_calls\u001B[39m\u001B[38;5;124m\"\u001B[39m: parallel_tool_calls,\n\u001B[1;32m    868\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprediction\u001B[39m\u001B[38;5;124m\"\u001B[39m: prediction,\n\u001B[1;32m    869\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpresence_penalty\u001B[39m\u001B[38;5;124m\"\u001B[39m: presence_penalty,\n\u001B[1;32m    870\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreasoning_effort\u001B[39m\u001B[38;5;124m\"\u001B[39m: reasoning_effort,\n\u001B[1;32m    871\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse_format\u001B[39m\u001B[38;5;124m\"\u001B[39m: response_format,\n\u001B[1;32m    872\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseed\u001B[39m\u001B[38;5;124m\"\u001B[39m: seed,\n\u001B[1;32m    873\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mservice_tier\u001B[39m\u001B[38;5;124m\"\u001B[39m: service_tier,\n\u001B[1;32m    874\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstop\u001B[39m\u001B[38;5;124m\"\u001B[39m: stop,\n\u001B[1;32m    875\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstore\u001B[39m\u001B[38;5;124m\"\u001B[39m: store,\n\u001B[1;32m    876\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m: stream,\n\u001B[1;32m    877\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream_options\u001B[39m\u001B[38;5;124m\"\u001B[39m: stream_options,\n\u001B[1;32m    878\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtemperature\u001B[39m\u001B[38;5;124m\"\u001B[39m: temperature,\n\u001B[1;32m    879\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtool_choice\u001B[39m\u001B[38;5;124m\"\u001B[39m: tool_choice,\n\u001B[1;32m    880\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtools\u001B[39m\u001B[38;5;124m\"\u001B[39m: tools,\n\u001B[1;32m    881\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtop_logprobs\u001B[39m\u001B[38;5;124m\"\u001B[39m: top_logprobs,\n\u001B[1;32m    882\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtop_p\u001B[39m\u001B[38;5;124m\"\u001B[39m: top_p,\n\u001B[1;32m    883\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m: user,\n\u001B[1;32m    884\u001B[0m             },\n\u001B[1;32m    885\u001B[0m             completion_create_params\u001B[38;5;241m.\u001B[39mCompletionCreateParams,\n\u001B[1;32m    886\u001B[0m         ),\n\u001B[1;32m    887\u001B[0m         options\u001B[38;5;241m=\u001B[39mmake_request_options(\n\u001B[1;32m    888\u001B[0m             extra_headers\u001B[38;5;241m=\u001B[39mextra_headers, extra_query\u001B[38;5;241m=\u001B[39mextra_query, extra_body\u001B[38;5;241m=\u001B[39mextra_body, timeout\u001B[38;5;241m=\u001B[39mtimeout\n\u001B[1;32m    889\u001B[0m         ),\n\u001B[1;32m    890\u001B[0m         cast_to\u001B[38;5;241m=\u001B[39mChatCompletion,\n\u001B[1;32m    891\u001B[0m         stream\u001B[38;5;241m=\u001B[39mstream \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    892\u001B[0m         stream_cls\u001B[38;5;241m=\u001B[39mStream[ChatCompletionChunk],\n\u001B[1;32m    893\u001B[0m     )\n",
      "File \u001B[0;32m/opt/miniconda3/envs/env_chatgptapi/lib/python3.13/site-packages/openai/_base_client.py:1283\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1269\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[1;32m   1270\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1271\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1278\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1279\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m   1280\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[1;32m   1281\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[1;32m   1282\u001B[0m     )\n\u001B[0;32m-> 1283\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest(cast_to, opts, stream\u001B[38;5;241m=\u001B[39mstream, stream_cls\u001B[38;5;241m=\u001B[39mstream_cls))\n",
      "File \u001B[0;32m/opt/miniconda3/envs/env_chatgptapi/lib/python3.13/site-packages/openai/_base_client.py:960\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    957\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    958\u001B[0m     retries_taken \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 960\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request(\n\u001B[1;32m    961\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m    962\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[1;32m    963\u001B[0m     stream\u001B[38;5;241m=\u001B[39mstream,\n\u001B[1;32m    964\u001B[0m     stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[1;32m    965\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39mretries_taken,\n\u001B[1;32m    966\u001B[0m )\n",
      "File \u001B[0;32m/opt/miniconda3/envs/env_chatgptapi/lib/python3.13/site-packages/openai/_base_client.py:1049\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1047\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m remaining_retries \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_retry(err\u001B[38;5;241m.\u001B[39mresponse):\n\u001B[1;32m   1048\u001B[0m     err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m-> 1049\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retry_request(\n\u001B[1;32m   1050\u001B[0m         input_options,\n\u001B[1;32m   1051\u001B[0m         cast_to,\n\u001B[1;32m   1052\u001B[0m         retries_taken\u001B[38;5;241m=\u001B[39mretries_taken,\n\u001B[1;32m   1053\u001B[0m         response_headers\u001B[38;5;241m=\u001B[39merr\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mheaders,\n\u001B[1;32m   1054\u001B[0m         stream\u001B[38;5;241m=\u001B[39mstream,\n\u001B[1;32m   1055\u001B[0m         stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[1;32m   1056\u001B[0m     )\n\u001B[1;32m   1058\u001B[0m \u001B[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001B[39;00m\n\u001B[1;32m   1059\u001B[0m \u001B[38;5;66;03m# to completion before attempting to access the response text.\u001B[39;00m\n\u001B[1;32m   1060\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mis_closed:\n",
      "File \u001B[0;32m/opt/miniconda3/envs/env_chatgptapi/lib/python3.13/site-packages/openai/_base_client.py:1098\u001B[0m, in \u001B[0;36mSyncAPIClient._retry_request\u001B[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1094\u001B[0m \u001B[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001B[39;00m\n\u001B[1;32m   1095\u001B[0m \u001B[38;5;66;03m# different thread if necessary.\u001B[39;00m\n\u001B[1;32m   1096\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(timeout)\n\u001B[0;32m-> 1098\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request(\n\u001B[1;32m   1099\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[1;32m   1100\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m   1101\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39mretries_taken \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1102\u001B[0m     stream\u001B[38;5;241m=\u001B[39mstream,\n\u001B[1;32m   1103\u001B[0m     stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[1;32m   1104\u001B[0m )\n",
      "File \u001B[0;32m/opt/miniconda3/envs/env_chatgptapi/lib/python3.13/site-packages/openai/_base_client.py:1049\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1047\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m remaining_retries \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_retry(err\u001B[38;5;241m.\u001B[39mresponse):\n\u001B[1;32m   1048\u001B[0m     err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m-> 1049\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retry_request(\n\u001B[1;32m   1050\u001B[0m         input_options,\n\u001B[1;32m   1051\u001B[0m         cast_to,\n\u001B[1;32m   1052\u001B[0m         retries_taken\u001B[38;5;241m=\u001B[39mretries_taken,\n\u001B[1;32m   1053\u001B[0m         response_headers\u001B[38;5;241m=\u001B[39merr\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mheaders,\n\u001B[1;32m   1054\u001B[0m         stream\u001B[38;5;241m=\u001B[39mstream,\n\u001B[1;32m   1055\u001B[0m         stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[1;32m   1056\u001B[0m     )\n\u001B[1;32m   1058\u001B[0m \u001B[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001B[39;00m\n\u001B[1;32m   1059\u001B[0m \u001B[38;5;66;03m# to completion before attempting to access the response text.\u001B[39;00m\n\u001B[1;32m   1060\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mis_closed:\n",
      "File \u001B[0;32m/opt/miniconda3/envs/env_chatgptapi/lib/python3.13/site-packages/openai/_base_client.py:1098\u001B[0m, in \u001B[0;36mSyncAPIClient._retry_request\u001B[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1094\u001B[0m \u001B[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001B[39;00m\n\u001B[1;32m   1095\u001B[0m \u001B[38;5;66;03m# different thread if necessary.\u001B[39;00m\n\u001B[1;32m   1096\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(timeout)\n\u001B[0;32m-> 1098\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request(\n\u001B[1;32m   1099\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[1;32m   1100\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m   1101\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39mretries_taken \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1102\u001B[0m     stream\u001B[38;5;241m=\u001B[39mstream,\n\u001B[1;32m   1103\u001B[0m     stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[1;32m   1104\u001B[0m )\n",
      "File \u001B[0;32m/opt/miniconda3/envs/env_chatgptapi/lib/python3.13/site-packages/openai/_base_client.py:1064\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1061\u001B[0m         err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m   1063\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1064\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1066\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_response(\n\u001B[1;32m   1067\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m   1068\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1072\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39mretries_taken,\n\u001B[1;32m   1073\u001B[0m )\n",
      "\u001B[0;31mRateLimitError\u001B[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if responce_list:\n",
    "        start_from = i\n",
    "except NameError:\n",
    "    responce_list = []\n",
    "    start_from = 0\n",
    "\n",
    "try:\n",
    "    for i in tqdm(range(len(eval_data[:]))):\n",
    "\n",
    "        if i < start_from:\n",
    "            continue\n",
    "        \n",
    "        sample = eval_data[i]\n",
    "        result = run_sample_with_openai(sample, eval_retriver, SYSTEM_PROMPT_ENTS, USER_PROMPT_ENTS)\n",
    "        responce_list.append(result)\n",
    "except Exception as e:\n",
    "    print(i)\n",
    "    print('Перезапустите VPN и запустите ячейку')\n",
    "    raise e\n",
    "\n",
    "assert len(responce_list) == len(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65156f80-d0fc-4129-8141-ba3ecde4ba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# responce_list = json.load(open('data/datasets/rubq_output_predicates_10.json'))\n",
    "# json.dump(responce_list, open('data/datasets/rubq_output_predicates_10.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f27a5f1c-3f15-4dab-9cc1-b23ca4fcab13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.527930012584744\n",
      "Recall:  0.5558397271952259\n",
      "F1:  0.5315268136240003\n"
     ]
    }
   ],
   "source": [
    "get_metrics(eval_data, responce_list, search_pattern='entity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81d7c7c0-6c68-4b4a-b06b-8dcf93c32ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_result(eval_data, eval_retriver, responce_list, search_pattern='entity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "805a0da6-a316-4408-9627-4b2c08a9324e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# json.dump(result, open('data/datasets/rubq_result_entities_100.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91f76e9a-6697-4b8c-bc5e-3c061f5d58bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1463f8-db5e-429b-9489-8658df6777d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "011df2c8-cb49-44e7-8e69-23a3dbb3bf0b",
   "metadata": {},
   "source": [
    "## Run Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85e501eb-01a0-48fa-9ae5-03cf6bc7202d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419 387\n",
      "retr 100: 0.9715762273901809\n",
      "retr 10: 0.8708010335917312\n"
     ]
    }
   ],
   "source": [
    "rubq_train = json.load(open(\"data/train_with_aliases.json\"))\n",
    "rubq_test = json.load(open(\"data/test_with_aliases.json\"))\n",
    "\n",
    "rubq_retr_prop_100 = json.load(open('data/retriver_out/rubq/rubq_test_predicates_retrieval.json'))\n",
    "rubq_retr_prop_10 = {k: dict(list(v.items())[:10]) for k, v in rubq_retr_prop_100.items()}\n",
    "\n",
    "rubq_test_eval = [sample for sample in rubq_test if str(sample['uid']) in rubq_retr_prop_100]\n",
    "\n",
    "print(len(rubq_test), len(rubq_test_eval))\n",
    "\n",
    "print(\n",
    "    f'retr 100: {np.mean([len(set(\n",
    "        [y.split(':')[-1] for y in x['question_props']]\n",
    "    ) & set(rubq_retr_prop_100[str(x['uid'])])) > 0 for x in rubq_test_eval])}',\n",
    "    f'retr 10: {np.mean([len(set(\n",
    "        [y.split(':')[-1] for y in x['question_props']]\n",
    "    ) & set(rubq_retr_prop_10[str(x['uid'])])) > 0 for x in rubq_test_eval])}',\n",
    "    sep='\\n'\n",
    ")\n",
    "\n",
    "eval_data = deepcopy(rubq_test_eval)\n",
    "eval_retriver = deepcopy(rubq_retr_prop_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12a1b865-169c-4df5-bb26-a299c9f30966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPARQL:  SELECT ?answer \n",
      "WHERE {\n",
      "  wd:Q131374 wdt:P20 [ wdt:P17 ?answer ].\n",
      "}\n",
      "\n",
      "QUESTION: In which country did the great Russian chess player Alexander Alekhine end his life?\n",
      "CANDIDATE PROPERTIES:\n",
      "P20: place of death -- most specific known (e.g. city instead of country, or hospital instead of city) death location of a person, animal or fictional character\n",
      "P27: country of citizenship -- the object is a country that recognizes the subject as its citizen\n",
      "P582: end time -- moment when an entity ceases to exist or a statement stops being valid\n",
      "P31: instance of -- that class of which this subject is a particular example and member; different from P279 (subclass of); for example: K2 is an instance of mountain; volcano is a subclass of mountain (and an instance of volcanic landform)\n",
      "P276: location -- location of the object, structure or event. In the case of an administrative entity as containing item use P131. For statistical entities use P8138. In the case of a geographic entity use P706. Use P7153 for locations associated with the object\n",
      "P26: spouse -- the subject has the object as their spouse (husband, wife, partner, etc.). Use \"unmarried partner\" (P451) for non-married companions\n",
      "P17: country -- sovereign state that this item is in (not to be used for human beings)\n",
      "P39: position held -- subject currently or formerly holds the object position or public office\n",
      "P580: start time -- time an entity begins to exist or a statement starts being valid\n",
      "P19: place of birth -- most specific known birth location of a person, animal or fictional character\n"
     ]
    }
   ],
   "source": [
    "test_prompt(eval_data, eval_retriver, USER_PROMPT_PROP, 144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c6c27a2-11ea-4d0e-aa48-39d98776d67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:  In which country did the great Russian chess player Alexander Alekhine end his life?\n",
      "SPARQL:  SELECT ?answer \n",
      "WHERE {\n",
      "  wd:Q131374 wdt:P20 [ wdt:P17 ?answer ].\n",
      "}\n",
      "\n",
      "The question specifically asks for the country where Alexander Alekhine, the Russian chess player, ended his life. The most relevant property to determine the country of someone's death is P20 (place of death), which is used to indicate the most specific known death location of a person. While P17 (country) is also relevant as it refers to the country associated with a certain item or event, it is not specifically about the death of a person. However, since the question is asking for the country, P17 can be considered relevant in this context as it directly pertains to the country associated with the death event.\n",
      "\n",
      "RELEVANT PROPERTIES: P20, P17\n"
     ]
    }
   ],
   "source": [
    "test_openai(eval_data, eval_retriver, SYSTEM_PROMPT_PROP, USER_PROMPT_PROP, 144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bf95fbe4-8a28-4492-80f7-414b67eb6906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 387/387 [07:59<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if responce_list:\n",
    "        start_from = i\n",
    "except NameError:\n",
    "    responce_list = []\n",
    "    start_from = 0\n",
    "\n",
    "try:\n",
    "    for i in tqdm(range(len(eval_data[:]))):\n",
    "\n",
    "        if i < start_from:\n",
    "            continue\n",
    "        \n",
    "        sample = eval_data[i]\n",
    "        result = run_sample_with_openai(sample, eval_retriver, SYSTEM_PROMPT_PROP, USER_PROMPT_PROP)\n",
    "        responce_list.append(result)\n",
    "except Exception as e:\n",
    "    print(i)\n",
    "    print('Перезапустите VPN и запустите ячейку')\n",
    "    raise e\n",
    "\n",
    "assert len(responce_list) == len(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "955725bf-0605-4dd2-a1eb-0c46f254900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "responce_list = json.load(open('data/datasets/rubq_output_properties_10.json'))\n",
    "# json.dump(responce_list, open('data/datasets/rubq_output_properties_100.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7a206806-0340-4db8-b1c8-3e9869562e64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.7665805340223943\n",
      "Recall:  0.7502153316106804\n",
      "F1:  0.7499569336778641\n"
     ]
    }
   ],
   "source": [
    "get_metrics(eval_data, responce_list, search_pattern='property')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c732ac8-b49a-4dd8-bff5-ebb63a0b168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_result(eval_data, eval_retriver, responce_list, search_pattern='property')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a30b53d-772b-4c68-8d69-192370a68336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "json.dump(result, open('data/datasets/rubq_result_properties_10.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c549a375-995b-426d-a938-4357fbff1432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b914db-3b94-454e-a339-fa94b44f3deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dbf44c-4c9a-4e54-afc6-073659df9fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83011fde-1578-43e0-a817-7ea3675b1bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7959aea7-8fa9-4bee-b92b-04f7220bb8af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912bd391-1d53-4e14-aef1-a0710bdf459c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a6535-315c-4c29-90a5-a2f183611637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5893cb68-4d39-40fe-b2bd-417cbc62df70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a404fe8e-9ad6-403e-bdd1-6a2bb49738be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa8725-2171-4f5c-a139-3ab3b2494432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42057688-348e-4da5-b0c2-97f3918fe296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fd836f-a898-4e77-b47b-04b1a5df6b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93745b5-0797-4de1-9db3-3c5a310e55bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece69ee8-8d10-42bf-8c5d-7681f7f228fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260eaccb-6fe3-48e0-931a-81ccd7bfa4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee131b4e-a615-4ddb-a4a0-317d96ded615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca253f0-df53-467a-96dd-0899d9e0cbd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9f87b3-eb07-4bc6-a6e9-fb6ecbae7834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fb405a-4f21-4ffe-9e34-b1f13a7c3935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e775e2-603c-4a07-88d3-804be2cd505e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea77f0a-e5ea-47f0-a3d5-f7b2c28be670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfc7a08-a906-480d-b68e-a6403f53ff2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f90ff63-2f1e-465a-b224-71e10d90a5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f20fb8-ea9a-47b5-8279-2a865d6a6f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5745a583-7b8c-4367-b8f3-81bc18e53d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d4a4f4-fb20-44a5-9c35-b19d7eb3b062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce28864-af17-4ab9-be29-e3d1f0a6e5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a6e84b-51e1-4df7-a8b3-884759a21d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c24d6d5-f8b9-49bb-9157-def639b6e443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcc5b1d-0120-4eac-b838-bda0434f3ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39343c08-1838-43f7-a493-96d5c0ea8c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85336a6b-509a-4cde-8c5f-614084bfdc50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8df515b-7fe8-4ed6-8b8f-bdcb64b37f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b123751-a643-4614-b0ae-26bf4f991d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828125b5-db7b-43cc-882e-a382ea775191",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel_chatgptapi",
   "language": "python",
   "name": "kernel_chatgptapi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
