{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4a48e7b2-2501-430e-a17c-4bd9d9f44380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import random\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648f9fc9-d120-44c6-ae4e-8ad8fa58de63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bfa68ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEW_SHOT_EXAMPLES_ENTS = \"\"\"\n",
    "                  EXAMPLE#1\n",
    "                   QUESTION: What does DiCaprio's full name sound like?\n",
    "                   CANDIDATE ENTITIES: \n",
    "                   Q116673393: Sibon irmelindicaprioae -- species of snake\n",
    "                    Q38111: Leonardo DiCaprio -- American actor and film producer (born 1974)\n",
    "                    Q11461: sound -- vibration that propagates as an acoustic wave\n",
    "                    Q36860035: DiCaprio -- family name\n",
    "                    Q25349951: Martin Scorsese and Leonardo DiCaprio -- collaborations\n",
    "                    Q56653813: DiCaprio 2 -- album by J.I.D\n",
    "                   RELEVANT ENTITIES: Q38111.\n",
    "                   \n",
    "                   \n",
    "                   EXAMPLE#2\n",
    "                   QUESTION: In which city near Moscow is the new Jerusalem monastery located?\n",
    "                    CANDIDATE ENTITIES: \n",
    "                    Q55502: Kingdom of Jerusalem -- medieval Christian kingdom in the Middle East\n",
    "                    Q773979: New Jerusalem Monastery -- monastery in Moscow Oblast, Russia\n",
    "                    Q1218: Jerusalem -- city in the Middle East, holy to the three Abrahamic religions\n",
    "                    Q649: Moscow -- capital and most populous city of Russia\n",
    "                    Q515: city -- large human settlement\n",
    "                    Q13164: Moscow State University -- university in Moscow, Russia\n",
    "                    Q6760: UTC+03:00 -- identifier for a time offset from UTC of +3\n",
    "                    Q10540001: Jerusalem -- family name                    \n",
    "                    RELEVANT ENTITIES: Q773979, Q649.\n",
    "\n",
    "                    \n",
    "                    EXAMPLE#3\n",
    "                    QUESTION: What capital stands on the banks of Potalaka?\n",
    "                    CANDIDATE ENTITIES: \n",
    "                    Q11626848: Mount Potalaka -- the mythical dwelling of the Buddhist bodhisattva Avalokiteśvara, said to exist in India\n",
    "                    Q22687: bank -- financial institution that accepts deposits\n",
    "                    Q60756888: Potalaka Guanyin -- sculpture by unknown artist (1965.556)\n",
    "                    Q179444: Potomac River -- river in the mid-Atlantic United States\n",
    "                    Q193893: capital -- upper part of a column (architecture)\n",
    "                    Q60: New York City -- most populous city in the United States\n",
    "                    Q5119: capital city -- primary governing city of a top-level (country) or first-level and second-level subdivision (country, state, province, regency, etc) political entity\n",
    "                    **Reasoning:**  \n",
    "                    - \"Capital\" refers to a **governing city**, not architectural elements (Q193893).  \n",
    "                    - \"Potalaka\" (Q11626848) is a **mythical** location, so no real-world capital is directly linked.  \n",
    "                    - Since no entity directly matches the question, **the most general applicable concept** is \"capital city\" (Q5119).\n",
    "                    RELEVANT ENTITIES: Q179444, Q5119.\n",
    "                    \n",
    "                    \n",
    "                    EXAMPLE#4 \n",
    "                    QUESTION: What is the official language of Brazil?  \n",
    "                    CANDIDATE ENTITIES:  \n",
    "                    Q750553: Spanish language -- Romance language originating in Spain  \n",
    "                    Q5146: Portuguese language -- Romance language, official in Portugal and Brazil  \n",
    "                    Q155: Brazil -- country in South America  \n",
    "                    Q483110: Brasília -- capital city of Brazil\n",
    "                    **Reasoning**:  \n",
    "                    - \"Official language\" refers to the main language used for governance.  \n",
    "                    - The description of Q5146 explicitly states it is official in Brazil.  \n",
    "                    - Q750553 (Spanish) is incorrect because it is **not** the official language.  \n",
    "                    - Q155 and Q483110 are related but not **languages**. \n",
    "                    RELEVANT ENTITIES: Q5146.  \n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT_ENTS = f\"\"\"You are an experienced WikiData user. \n",
    "                   You receive a QUESTION and a SET of extracted Wikidata CANDIDATE ENTITIES, retrieved from an index based on similarity between the QUESTION and the ENTITY. \n",
    "                   Each entity has a wikidata ID, label and description in a form of Wikidata ID: label -- description. \n",
    "                   Your task is to select only the most semantically relevant entities based on their labels and descriptions.\n",
    "                   \n",
    "                   Instruction:\n",
    "                    -- Ignore entities that are loosely related, homonyms, or have indirect contextual links to the QUESTION.\n",
    "                    -- If no entity perfectly matches the question, select the best available entity based on contextual closeness.\n",
    "                    -- If multiple entities seem relevant, prefer those with a stronger direct connection to the query subject.\n",
    "                    -- If there are ambiguous entities that relate to the different countries, ALWAYS choose the entity that is related to Russia, based on description.\n",
    "                    -- Some questions may have multiple correct entities. Return all entities that are directly relevant. Do NOT include entities that are only indirectly related (e.g., broad categories like 'city' instead of a specific location).\n",
    "                    -- DO NOT reject entity, if it fits to the entity mentioned in query, but DOES NOT DIRECTLY answer the question.\n",
    "                    -- Always include reasoning in the beginning of the responce.\n",
    "                    -- Always place \"RELEVANT ENTITIES: ...\" at the end of your response.\n",
    "\n",
    "                   Here are examples:\n",
    "                   {FEW_SHOT_EXAMPLES_ENTS}\n",
    "                   \"\"\"\n",
    "\n",
    "USER_PROMPT_ENTS = \"\"\"QUESTION: {question}\\nCANDIDATE ENTITIES:\\n{candidate_list_str}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "371f2070-9e7d-4a03-a910-9276fce3419d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEW_SHOT_EXAMPLES_PROP = \"\"\"\n",
    "                    EXAMPLE#1\n",
    "                    QUESTION: How much does Nurmagomedov weigh?\n",
    "                    CANDIDATE PROPERTIES:\n",
    "                    P166: award received -- award or recognition received by a person, organization or creative work\n",
    "                    P54: member of sports team -- sports teams or clubs that the subject represents or represented\n",
    "                    P1082: population -- number of people inhabiting the place; number of people of subject\n",
    "                    P1351: number of points/goals/set scored -- goals / points scored in a match or an event used as qualifier to the participant. Use P1358 for league points.\n",
    "                    P1350: number of matches played/races/starts -- matches or games a player or a team played during an event. Also a total number of matches a player officially appeared in during the whole career.\n",
    "                    P2121: prize money -- amount in a specific currency\n",
    "                    P585: point in time -- date something took place, existed or a statement was true; for providing time use the \"refine date\" property (P4241)\n",
    "                    P2067: mass -- mass (in colloquial usage also known as weight) of the item\n",
    "                    P1412: languages spoken, written or signed -- language(s) that a person or a people speaks, writes or signs, including the native language(s)\n",
    "                    P2046: area -- area occupied by an object\n",
    "                    RELEVANT PROPERTIES: P2067\n",
    "\n",
    "\n",
    "                    EXAMPLE#2\n",
    "                    QUESTION: Where is the Academy of Sciences of Armenia located\n",
    "                    CANDIDATE PROPERTIES:\n",
    "                    P463: member of -- organization, club or musical group to which the subject belongs. Do not use for membership in ethnic or social groups, nor for holding a political position, such as a member of parliament (use P39 for that)\n",
    "                    P31: instance of -- that class of which this subject is a particular example and member; different from P279 (subclass of); for example: K2 is an instance of mountain; volcano is a subclass of mountain (and an instance of volcanic landform)\n",
    "                    P19: place of birth -- most specific known birth location of a person, animal or fictional character\n",
    "                    P580: start time -- time an entity begins to exist or a statement starts being valid\n",
    "                    P582: end time -- moment when an entity ceases to exist or a statement stops being valid\n",
    "                    P69: educated at -- educational institution attended by subject\n",
    "                    P159: headquarters location -- city or town where an organization's headquarters is or has been situated. Use P276 qualifier for specific building\n",
    "                    P585: point in time -- date something took place, existed or a statement was true; for providing time use the \"refine date\" property (P4241)\n",
    "                    RELEVANT PROPERTIES: P159\n",
    "\n",
    "\n",
    "                    EXAMPLE#3\n",
    "                    QUESTION: What is the singing voice of Dmitri Hvorostovsky?\n",
    "                    CANDIDATE PROPERTIES:\n",
    "                    P412: voice type -- person's voice type. expected values: soprano, mezzo-soprano, contralto, countertenor, tenor, baritone, bass (and derivatives)\n",
    "                    P725: voice actor -- performer of a spoken role in a creative work such as animation, video game, radio drama, or dubbing over [use \"character role\" (P453) as qualifier] [use \"cast member\" (P161) for live acting]\n",
    "                    P175: performer -- actor, musician, band or other performer associated with this role or musical work\n",
    "                    P453: character role -- specific role played or filled by subject -- use only as qualifier of \"cast member\" (P161), \"voice actor\" (P725)\n",
    "                    P179: part of the series -- series which contains the subject\n",
    "                    P674: characters -- characters which appear in this item (like plays, operas, operettas, books, comics, films, TV series, video games)\n",
    "                    P1441: present in work -- this (fictional or fictionalized) entity, place, or person appears in that work as part of the narration (use P2860 for works citing other works, P361/P1433 for works being part of other works, P1343 for entities described in non-fictional accounts)\n",
    "                    **Reasoning:** \n",
    "                    - the question asks about voice's characteristics of some person\n",
    "                    - P412 is relevant, because it's a property described a voice type, which is voice's characteristic\n",
    "                    - P725, P175, P674 represent properties described a person role in something, not related to voice\n",
    "                    - other properties also represent something not similar to voice \n",
    "                    RELEVANT PROPERTIES: P412\n",
    "                   \n",
    "                   \n",
    "                    EXAMPLE#4\n",
    "                    QUESTION: Who was S. V. Mikhalkov's co-author in writing the text of the anthem of the Soviet Union?\n",
    "                    CANDIDATE PROPERTIES:\n",
    "                    P31: instance of -- that class of which this subject is a particular example and member; different from P279 (subclass of); for example: K2 is an instance of mountain; volcano is a subclass of mountain (and an instance of volcanic landform)\n",
    "                    P86: composer -- person(s) who wrote the music [for lyricist, use \"lyrics by\" (P676)]\n",
    "                    P1412: languages spoken, written or signed -- language(s) that a person or a people speaks, writes or signs, including the native language(s)\n",
    "                    P92: main regulatory text -- text setting the main rules by which the subject is regulated\n",
    "                    P50: author -- main creator(s) of a written work (use on works, not humans); use P2093 (author name string) when Wikidata item is unknown or does not exist\n",
    "                    P155: follows -- immediately prior item in a series of which the subject is a part, preferably use as qualifier of P179 [if the subject has replaced the preceding item, e.g. political offices, use \"replaces\" (P1365)]\n",
    "                    P676: lyricist -- author of song lyrics\n",
    "                    **Reasoning:** \n",
    "                    - the question asks about an co-author of a some national anthem's text, not the music itself!\n",
    "                    - description of P676 makes it clear that it represent \"author of song lyrics\" - that's what we needed\n",
    "                    - P31's description is too general and not correspond to songs's author\n",
    "                    - P86, P50 are close, but they describe a composer/author of written work, not a lyrics writer\n",
    "                    - other properties also describe something another than lyric's writer\n",
    "                    RELEVANT PROPERTIES: P676\n",
    "\n",
    "\n",
    "                    EXAMPLE#5\n",
    "                    QUESTION: In which country did the great Russian chess player Alexander Alekhine end his life?\n",
    "                    CANDIDATE PROPERTIES:\n",
    "                    P20: place of death -- most specific known (e.g. city instead of country, or hospital instead of city) death location of a person, animal or fictional character\n",
    "                    P27: country of citizenship -- the object is a country that recognizes the subject as its citizen\n",
    "                    P582: end time -- moment when an entity ceases to exist or a statement stops being valid\n",
    "                    P31: instance of -- that class of which this subject is a particular example and member; different from P279 (subclass of); for example: K2 is an instance of mountain; volcano is a subclass of mountain (and an instance of volcanic landform)\n",
    "                    P276: location -- location of the object, structure or event. In the case of an administrative entity as containing item use P131. For statistical entities use P8138. In the case of a geographic entity use P706. Use P7153 for locations associated with the object\n",
    "                    P26: spouse -- the subject has the object as their spouse (husband, wife, partner, etc.). Use \"unmarried partner\" (P451) for non-married companions\n",
    "                    P17: country -- sovereign state that this item is in (not to be used for human beings)\n",
    "                    P39: position held -- subject currently or formerly holds the object position or public office\n",
    "                    P580: start time -- time an entity begins to exist or a statement starts being valid\n",
    "                    P19: place of birth -- most specific known birth location of a person, animal or fictional character\n",
    "                    **Reasoning:**\n",
    "                    - the question asks about location of somebody's death and it's country where it happened\n",
    "                    - in the candidates we can clearly see P20 and P17, which respresent **place of death** and **contry**\n",
    "                    - P276 and P582 are close, but too common for this QUESTION\n",
    "                    - other has no relation to QUESTION's PROPERTIES\n",
    "                    RELEVANT PROPERTIES: P20, P17\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT_PROP = f\"\"\"You are an experienced WikiData user. \n",
    "                   You receive a QUESTION and a SET of extracted Wikidata CANDIDATE PROPERTIES, retrieved from an index based on similarity between the QUESTION and the PROPERTY. \n",
    "                   Each property has a wikidata ID, label and description in a form of Wikidata ID: label -- description. \n",
    "                   Your task is to select only the most semantically relevant properties based on their labels and descriptions.\n",
    "                   \n",
    "                   Instruction:\n",
    "                    -- Ignore properties that are loosely related, homonyms, or have indirect contextual links to the QUESTION.\n",
    "                    -- If no property perfectly matches the question, select the best available property based on contextual closeness.\n",
    "                    -- If multiple properties seem relevant, prefer those with a stronger direct connection to the query subject.\n",
    "                    -- Some questions may have multiple correct properties. Return all properties that are directly relevant. \n",
    "                    -- Always include reasoning in the beginning of the responce.\n",
    "                    -- Always place \"RELEVANT PROPERTIES: ...\" at the end of your response.\n",
    "\n",
    "                   Here are examples:\n",
    "                   {FEW_SHOT_EXAMPLES_PROP}\n",
    "                   \"\"\"\n",
    "\n",
    "USER_PROMPT_PROP = \"\"\"QUESTION: {question}\\nCANDIDATE PROPERTIES:\\n{candidate_list_str}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aa24ff-c0e9-410c-97b0-6e6dc26eceb3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e9996c2-88db-436f-a75d-1646bb273956",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Prompt and Preprocessing Functions\n",
    "'''\n",
    "\n",
    "def get_default(dic, field, default=''):\n",
    "    return dic[field] if field in dic else default\n",
    "\n",
    "    \n",
    "def prepare_candidates(sample, retriever_output):    \n",
    "    sample_id = sample['id']\n",
    "    # relevant_ids = list(sample['id2alias'].keys())\n",
    "    retrived_cands = retriever_output[str(sample_id)]\n",
    "    retrived_ids = retrived_cands.keys()\n",
    "    retrived_ids = list(filter(lambda x: x is not None, retrived_ids))\n",
    "    \n",
    "    candidates_set = list(set(retrived_ids\n",
    "                              # + relevant_ids\n",
    "                             ))\n",
    "    # HERE I DO SHUFFLING, SINCE I DO NOT KNOW THE ORDER FROM RETRIEVER\n",
    "    random.shuffle(candidates_set)\n",
    "    \n",
    "    entities_list = [f\"{key}: {get_default(retrived_cands[key], 'label')} -- {get_default(retrived_cands[key], 'description')}\" for key in retrived_ids]\n",
    "    entities_str = \"\\n\".join(entities_list)\n",
    "    return entities_str\n",
    "        \n",
    "\n",
    "def construct_user_prompt(sample, retriever_output, user_prompt):\n",
    "    question = sample['en_question']\n",
    "    candidates_set_string = prepare_candidates(sample, retriever_output)\n",
    "    user_prompt = user_prompt.format(question=question, candidate_list_str=candidates_set_string)\n",
    "    return user_prompt\n",
    "\n",
    "\n",
    "def create_batch_file(batch_data, batch_retriver, system_prompt, user_prompt):\n",
    "    file = []\n",
    "    for i in range(len(batch_data)):\n",
    "        messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                  {\"role\": \"user\", \"content\": construct_user_prompt(batch_data[i], batch_retriver, user_prompt)}]\n",
    "        new_request = {\"custom_id\": f\"request_{i}\", \n",
    "                       \"method\": \"POST\", \n",
    "                       \"url\": \"/v1/chat/completions\", \n",
    "                       \"body\": {\"model\": \"gpt-4-1106-preview\", \n",
    "                                \"messages\": messages, \n",
    "                                \"temperature\": 0,\n",
    "                                \"max_tokens\": 400,\n",
    "                                \"top_p\": 1,\n",
    "                                \"frequency_penalty\": 0,\n",
    "                                \"presence_penalty\": 0,\n",
    "                                # \"response_format\": {\"type\": \"json_object\"}\n",
    "                               }}\n",
    "        file.append(new_request)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d1319c85-9dcd-4466-994b-addaeacf298e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Run OpenAI Functions\n",
    "'''\n",
    "def ask_openai_batch(file_path):\n",
    "    client = openai.OpenAI(\n",
    "        api_key=os.environ.get(\"OPENAI_KEY\"),\n",
    "    )\n",
    "\n",
    "    batch_input_file = client.files.create(file=open(file_path, 'rb'), purpose='batch')\n",
    "    batch_input_file_id = batch_input_file.id\n",
    "\n",
    "    response_batch = None\n",
    "    idx = 0\n",
    "    while response_batch is None and idx < 10:\n",
    "        try:\n",
    "            response_batch = client.batches.create(\n",
    "                input_file_id=batch_input_file_id,\n",
    "                endpoint=\"/v1/chat/completions\",\n",
    "                completion_window='24h',\n",
    "            )\n",
    "            idx += 1\n",
    "            \n",
    "        except openai.APIConnectionError as e:\n",
    "            idx += 1\n",
    "            print(e)\n",
    "\n",
    "    if idx == 10:\n",
    "        return \"This sentence was not judged.\"\n",
    "\n",
    "    return response_batch\n",
    "\n",
    "\n",
    "def check_batch(batch_id):\n",
    "    client = openai.OpenAI(\n",
    "        api_key=os.environ.get(\"OPENAI_KEY\"),\n",
    "    )\n",
    "\n",
    "    return client.batches.retrieve(batch_id)\n",
    "\n",
    "def get_response_batch(batch_id):\n",
    "    client = openai.OpenAI(\n",
    "        api_key=os.environ.get(\"OPENAI_KEY\"),\n",
    "    )\n",
    "    file_response = client.files.content(batch_id)\n",
    "        \n",
    "    response_data = []\n",
    "    for line in file_response.iter_lines():\n",
    "        answer_dict = eval(line.replace('null', 'None'))\n",
    "        answer_str = answer_dict['response']['body']['choices'][0]['message']['content']\n",
    "        response_data.append(answer_str)\n",
    "\n",
    "    return response_data\n",
    "\n",
    "def get_usage_info(batch_id):\n",
    "    client = openai.OpenAI(\n",
    "        api_key=os.environ.get(\"OPENAI_KEY\"),\n",
    "    )\n",
    "    file_response = client.files.content(check_batch(id_).output_file_id)\n",
    "\n",
    "    prompt_tokens_total, completion_tokens_total = 0, 0\n",
    "    for line in file_response.iter_lines():\n",
    "        answer_dict = eval(line.replace('null', 'None'))\n",
    "        usage = answer_dict['response']['body']['usage']\n",
    "        prompt_tokens_total += usage['prompt_tokens']\n",
    "        completion_tokens_total += usage['completion_tokens']\n",
    "    return {\n",
    "        'prompt_tokens': prompt_tokens_total, \n",
    "        'completion_tokens': completion_tokens_total\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78a57a4d-8009-4604-9608-1b90473801e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Eval Functions\n",
    "'''\n",
    "def extract_wikidata_ids(text, search_pattern):\n",
    "    pattern = search_pattern + r\"\\s*([\\w, ]+)\"    \n",
    "    match = re.search(pattern, text)\n",
    "    \n",
    "    if match:\n",
    "        # Extract the IDs and return them as a list\n",
    "        wikidata_ids = match.group(1).split(', ')\n",
    "        return wikidata_ids\n",
    "    else:\n",
    "        return []\n",
    "        \n",
    "# RELEVANT ENTITIES: / RELEVANT PROPERTIES:\n",
    "def parse_responce(responce_str, search_pattern):\n",
    "    if search_pattern == 'entity':\n",
    "        search_pattern = 'RELEVANT ENTITIES:'\n",
    "    elif search_pattern == 'property':\n",
    "        search_pattern = 'RELEVANT PROPERTIES:'\n",
    "    else:\n",
    "        raise Exception('Choose correct seacrh pattern')\n",
    "    \n",
    "    # parse main case\n",
    "    if search_pattern in responce_str:\n",
    "        wikidata_ids = extract_wikidata_ids(responce_str, search_pattern)\n",
    "        return wikidata_ids\n",
    "    # I hope there are no other cases, but still -- better to ch\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_metrics(eval_data, response_data, search_pattern, gold_key):\n",
    "\n",
    "    assert len(eval_data) == len(response_data)\n",
    "\n",
    "    get_gold = lambda x: x[gold_key]['query'].keys()\n",
    "    \n",
    "    overall_precision, overall_recall, overall_f1 = 0, 0, 0\n",
    "    failed_examples = []\n",
    "    error_generations, incomplete_generation = [], []\n",
    "    false_positive_generations = []\n",
    "    for idx, pair in enumerate(zip(eval_data, response_data)):\n",
    "        sample, gpt_response = pair\n",
    "        extracted_candidates = parse_responce(gpt_response, search_pattern)\n",
    "\n",
    "        gold_ids = get_gold(sample)\n",
    "        \n",
    "        if extracted_candidates:\n",
    "            true_positives = set(extracted_candidates) & set(gold_ids)\n",
    "    \n",
    "            precision = len(true_positives) / len(extracted_candidates) if extracted_candidates else 0.0\n",
    "            if precision == 0:\n",
    "                false_positive_generations.append([idx, gpt_response, gold_ids])\n",
    "    \n",
    "            # Recall: Proportion of gold entities that are correctly predicted\n",
    "            recall = len(true_positives) / len(gold_ids) if gold_ids else 0.0\n",
    "            if recall == 0:\n",
    "                error_generations.append([idx, gpt_response, gold_ids])\n",
    "            if recall != 1:\n",
    "                incomplete_generation.append([idx, gpt_response, gold_ids])\n",
    "    \n",
    "            # F1-Score: Harmonic mean of Precision and Recall\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0.0\n",
    "    \n",
    "            overall_precision += precision\n",
    "            overall_recall += recall\n",
    "            overall_f1 += f1\n",
    "        else:\n",
    "            failed_examples.append(gpt_response)\n",
    "        \n",
    "    overall_precision /= len(response_data)\n",
    "    overall_recall /= len(response_data)\n",
    "    overall_f1 /= len(response_data)\n",
    "    \n",
    "    print('Precision: ', overall_precision)\n",
    "    print('Recall: ', overall_recall)\n",
    "    print('F1: ', overall_f1)\n",
    "\n",
    "\n",
    "def get_result(data, retriver_output, response_arr, search_pattern):\n",
    "    result = {}\n",
    "    for idx, pair in enumerate(zip(data, response_arr)):\n",
    "        sample, gpt_response = pair\n",
    "        extracted_candidates = parse_responce(gpt_response, search_pattern)\n",
    "        uid = str(sample['id'])\n",
    "        result[uid] = {\n",
    "            'question_eng': sample['en_question'],\n",
    "            'query': sample['query'],\n",
    "            'candidates': {cand: retriver_output[uid][cand]['label']\n",
    "                           for cand in extracted_candidates if cand in retriver_output[uid]} if extracted_candidates else {}\n",
    "        }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c103dd-6e7f-4a54-af64-011ba2e86725",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f56af167-c0f3-43a5-8c92-00e6c189d8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data) = 480\n",
      "len(eval) = 479\n",
      "retr 100 = 0.7369519832985386\n"
     ]
    }
   ],
   "source": [
    "task_name = 'entity' # entity / property\n",
    "data_name = 'rubq'\n",
    "retriver_out_path = 'data/retriver_out/rubq/rubq_test_entities_retrieval.json'\n",
    "data_path = 'data/preprocessed/rubq/rubq_test.json'\n",
    "topk = 100\n",
    "\n",
    "retriver_out = json.load(open(retriver_out_path))\n",
    "retriver_out = {k: dict(list(v.items())[:topk]) for k, v in retriver_out.items()}\n",
    "\n",
    "data = json.load(open(data_path))['dataset']\n",
    "eval_data = [sample for sample in data if str(sample['id']) in retriver_out]\n",
    "\n",
    "if task_name == 'entity':\n",
    "    SYSTEM_PROMPT = SYSTEM_PROMPT_ENTS\n",
    "    USER_PROMPT = USER_PROMPT_ENTS\n",
    "    retr_field = 'entities'\n",
    "elif task_name == 'property':\n",
    "    SYSTEM_PROMPT = SYSTEM_PROMPT_PROP\n",
    "    USER_PROMPT = USER_PROMPT_PROP\n",
    "    retr_field = 'relations'\n",
    "else:\n",
    "    raise Exception('Choose correct task_name')\n",
    "\n",
    "print(\n",
    "    f'len(data) = {len(data)}', \n",
    "    f'len(eval) = {len(eval_data)}',\n",
    "    f'retr {topk} = {np.mean([len(\n",
    "        set(x[retr_field]['query'].keys()) & \n",
    "        set(retriver_out[str(x['id'])])\n",
    "    ) > 0 for x in eval_data])}',\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d671708c-2dce-4fcb-9fae-d003773105a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f029c0fe-8997-42a9-a318-12cf908db7bc",
   "metadata": {},
   "source": [
    "## Post to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e47e499f-e565-41ea-b04c-525ab68ceb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_per_1m = {'prompt': 5, 'completion': 15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ab933f2-f094-45a8-a3be-6afeaacd0817",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_file = create_batch_file(eval_data, retriver_out, SYSTEM_PROMPT, USER_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "029e4ddb-f9c7-458f-8abf-ca3cdd7a563a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Q12994', 'Q157070'])\n",
      "dict_keys(['P582', 'P131'])\n",
      "======\n",
      "QUESTION: When did Bruges die in Flanders County?\n",
      "CANDIDATE ENTITIES:\n",
      "Q663749: judicial arrondissement of Bruges -- former judicial arrondissement of Belgium\n",
      "Q111814592: why some whales die on land: first whale did so -- narrative motif documented in Thompson's Motif-Index of Folk-Literature\n",
      "Q104472038: The funeral of Charles I, Count of Flanders, celebrated in Bruges in the Church of St. Christopher on 22 April 1127 -- painting by Jan Van Beers\n",
      "Q17101798: Exposition des primitifs flamands à Bruges -- exhibition in 1902 about Early Netherlandish Painting, Bruges,\n",
      "Q47578200: Did Jesus die of a 'broken heart'? -- scientific article published in August 2009\n",
      "Q157070: County of Flanders -- A county and historic territory in the Low Countries\n",
      "Q35088344: Characteristics of Chinese rural young suicides: who did not have a strong intent to die. -- scientific article\n",
      "Q40798683: 'In an important way, I did die': uncertainty and revival in persons living with HIV or AIDS. -- scientific article\n",
      "Q93182418: Grow Smart and Die Young: Why Did Cephalopods Evolve Intelligence? -- scientific article published on 13 November 2018\n",
      "Q50894485: Mortality in the Survival With ORal D-sotalol (SWORD) trial: why did patients die? -- scientific article published in April 1998\n",
      "Q35688208: Communication on end-of-life decisions with patients wishing to die at home: the making of a guideline for GPs in Flanders, Belgium -- scientific article published on January 2006\n",
      "Q30353639: Why did many more diamond miners than gold miners die in South Africa during the 1918 influenza pandemic? -- scientific article\n",
      "Q33249093: Where do the elderly die? The impact of nursing home utilisation on the place of death. Observations from a mortality cohort study in Flanders. -- scientific article\n",
      "Q92278495: How fast did newborns die in Nigeria from 2009-2013: a time-to-death analysis using Verbal /Social Autopsy data -- scientific article published on 01 December 2019\n",
      "Q12994: Bruges -- city in West Flanders, Belgium\n",
      "Q115979585: Arthur Van Rolleghem -- priest, teacher, curate, matricularius, assistant chaplain, director and chaplain (1867-1917)\n",
      "Q16684024: Emergency zone East Flanders Center -- fire and emergency response zone around Ghent, Belgium\n",
      "Q90948: Arrondissement of Ghent -- 1 of 43 administrative arrondissements of Belgium\n",
      "Q56958365: Did Caravaggio die of Staphylococcus aureus sepsis? -- scientific article published on 17 September 2018\n",
      "Q50547859: Why did some Danish counties introduce breast cancer screening and others not? An exploratory study of four selected counties -- scientific article published in January 2008\n",
      "Q102129201: grave marker of Petrus Calf -- grave marker in lead, late Middle Ages, location of discovery: Bruges, collection: Raakvlak, BR79/OLVK/1/2/1\n",
      "Q102129239: roof decoration in red earthenware -- roof decoration in red earthenware, late Middle Ages, location of discovery: Bruges, collection: Raakvlak, BR/L.V./34\n",
      "Q31154739: What did they know? And when did they know it? Progress in helping clinicians reach decisions -- scientific article\n",
      "Q91388: Arrondissement of Kortrijk -- 1 of 43 administrative arrondissements of Belgium\n",
      "Q102129202: grave marker of Nikolaas Van der Steene -- grave marker in lead, late Middle Ages, location of discovery: Bruges, collection: Raakvlak, BR79/OLVK/1/5/1\n",
      "Q62085959: Radler-Streifzüge durch die Mark Brandenburg -- German road book series by Oskar Kilian, 1898/1899\n",
      "Q28646900: Foreign Medical Teams in the Philippines after Typhoon Haiyan 2013 - Who Were They, When Did They Arrive and What Did They Do? -- scientific article\n",
      "Q21675422: Portraits of Filips Dominicle and Barbara Ommejaeghere -- painting by an anonymous painter from Bruges, middle of the 16th-century\n",
      "Q4865212: Bartholomaeus of Bruges -- Flemish physician and natural philosopher\n",
      "Q64103681: Smoke-free environment policy in Vietnam: what did people see and how did they react when they visited various public places? -- scholarly article published March 2019\n",
      "Q1432260: Ostend-Bruges International Airport -- airport\n",
      "Q115818424: Achiel Piepers -- Belgian priest, teacher and school director (1871 - 1928)\n",
      "Q19156053: Der Börsen- und Gründungsschwindel in Berlin -- German article series in: Die Gartenlaube, 1874-1875\n",
      "Q335595: judicial arrondissement of Veurne -- former judicial arrondissement of Belgium\n",
      "Q19233189: Vernünftige Gedanken einer Hausmutter -- German article series in: Die Gartenlaube\n",
      "Q62904613: Red touches in the landscape of Flanders County -- article published in 2018\n",
      "Q26757474: The Leguenay Bridge, Bruges -- painting by Maxime Maufra\n",
      "Q90921: Arrondissement of Aalst -- 1 of 43 administrative arrondissements of Belgium\n",
      "Q651811: Tielt -- city in West Flanders, Belgium\n",
      "Q21131908: When did Carcharocles megalodon become extinct? A new analysis of the fossil record -- scientific article published in 2014\n",
      "Q102113272: buckle in bone -- buckle in bone, high Middle Ages, location of discovery: Bruges, collection: Raakvlak, 93007/1/1/1\n",
      "Q115837633: Louis Vanheule -- Belgian priest, teacher and school director (1815 - 1890)\n",
      "Q30152139: Spatiotemporal Co-occurrence of Flanders and West Nile Viruses Within Culex Populations in Shelby County, Tennessee -- scientific article\n",
      "Q981450: Louis de Gruuthuse -- Louis de Bruges; ca. 1427-1492; married Marguerite de Borselen in 1455; noted diplomat and bibliophile\n",
      "Q13122: Dendermonde -- city in East Flanders, Belgium\n",
      "Q91450: Arrondissement of Ypres -- 1 of 43 administrative arrondissements of Belgium\n",
      "Q1108949: Gruuthusemuseum -- museum in Bruges, Belgium\n",
      "Q1158157: Ned Flanders -- fictional character from The Simpsons franchise\n",
      "Q234: Flanders -- land of the Flemish people\n",
      "Q38630287: First-trimester smoking cessation in pregnancy did not increase the risk of preeclampsia/eclampsia: A Murmansk County Birth Registry study -- scientific article published on 10 August 2017\n",
      "Q111442155: core complex die -- a chiplet component of AMD Zen processors\n",
      "Q21079104: William Bruges -- English politician.\n",
      "Q110618917: Cityscape of Bruges, called The Seven Wonders of Bruges -- painting by Pieter Claeissens\n",
      "Q100975452: bottle in glass -- bottle in glass, early modern period, location of discovery: Bruges, collection: Raakvlak, BR99/J/1B/551b\n",
      "Q917183: Church of Our Lady -- church in Bruges, Belgium\n",
      "Q115982755: Leo Fidelis Van den Poel -- priest, curate, school director and missionary (1790 - 1837)\n",
      "Q102113381: jug in tin-lead alloy -- jug in tin-lead alloy, late Middle Ages, location of discovery: Bruges, collection: Raakvlak, col Beuck/1/1/A/252\n",
      "Q102129274: bag clasp in brass -- bag clasp in brass, late Middle Ages/early modern period, location of discovery: Bruges, collection: Raakvlak, BR86/SPIE-SPR/1\n",
      "Q107439871: jug in red earthenware -- jug in red earthenware, late Middle Ages, location of discovery: Bruges, collection: Raakvlak, BR88/PSK/B/13\n",
      "Q102113345: drinking glass -- drinking glass, late Middle Ages, location of discovery: Bruges, collection: Raakvlak, BR90/GAR/1/1/B/11\n",
      "Q115095683: magic birds die when owner is killed -- narrative motif documented in Thompson's Motif-Index of Folk-Literature\n",
      "Q2213896: Zapovit -- 1845 poem by Taras Shevchenko\n",
      "Q1114: East Flanders -- province in Flanders, Belgium\n",
      "Q612523: Moll Flanders -- novel by Daniel Defoe\n",
      "Q100975669: jug in proto stoneware -- jug in proto stoneware, late Middle Ages, location of discovery: Bruges, collection: Raakvlak, 93008/1/15/b/1\n",
      "Q100975701: jug in grey earthenware -- jug in grey earthenware, late Middle Ages, location of discovery: Bruges, collection: Raakvlak, BR90/GAR/2/7A/1\n",
      "Q100975708: jug in stoneware -- jug in stoneware, late Middle Ages, location of discovery: Bruges, collection: Raakvlak, BR84-85/RP/1/13/A/1\n",
      "Q100975712: jug in glazed stoneware -- jug in glazed stoneware, late Middle Ages, location of discovery: Bruges, collection: Raakvlak, BR/L.V./14\n",
      "Q100975730: jug in red earthenware -- jug in red earthenware, early modern period, location of discovery: Bruges, collection: Raakvlak, BR14/EZ/1/4/A/196\n",
      "Q100976022: bowl in red earthenware -- bowl in red earthenware, early modern period, location of discovery: Bruges, collection: Raakvlak, BR14/EZ/1/4/A/171\n",
      "Q100976049: bowl in red earthenware -- bowl in red earthenware, early modern period, location of discovery: Bruges, collection: Raakvlak, BR14/EZ/1/4/A/127\n",
      "Q100976054: bowl in red earthenware -- bowl in red earthenware, early modern period, location of discovery: Bruges, collection: Raakvlak, BR14/EZ/1/4/A/137\n",
      "Q100976056: bowl in red earthenware -- bowl in red earthenware, early modern period, location of discovery: Bruges, collection: Raakvlak, BR14/EZ/1/4/A/212\n",
      "Q100976063: jug in glazed stoneware -- jug in glazed stoneware, late Middle Ages, location of discovery: Bruges, collection: Raakvlak, BR/L.V./1/1/A/50\n",
      "Q100976893: ointment jar in red earthenware -- ointment jar in red earthenware, early modern period, location of discovery: Bruges, collection: Raakvlak, 92007/1/3/146\n",
      "Q100977405: bowl with panhandle in red earthenware -- bowl with panhandle in red earthenware, early modern period, location of discovery: Bruges, collection: Raakvlak, BR10/LR/2/256/2\n",
      "Q102113319: flute in silver -- flute in silver, high Middle Ages, location of discovery: Bruges, collection: Raakvlak, BR16/HO/1\n",
      "Q102113386: jar in tin-lead alloy -- jar in tin-lead alloy, late Middle Ages, location of discovery: Bruges, collection: Raakvlak, col Beuck/1/1/A/258\n",
      "Q102129166: drainpipe in red earthenware -- drainpipe in red earthenware, early modern period, location of discovery: Bruges, collection: Raakvlak, BR14/EZ/1/4/A/178\n",
      "Q102129185: buckle in copper alloy -- buckle in copper alloy, early modern period, location of discovery: Bruges, collection: Raakvlak, BR/VD/1/1/A/103\n",
      "Q102129187: buckle in copper alloy -- buckle in copper alloy, late Middle Ages, location of discovery: Bruges, collection: Raakvlak, BR/VD/1/1/A/108\n",
      "Q102129189: buckle in copper alloy -- buckle in copper alloy, late Middle Ages, location of discovery: Bruges, collection: Raakvlak, BR/VD/1/1/A/124\n",
      "Q102129223: marble in red earthenware -- marble in red earthenware, early modern period, location of discovery: Bruges, collection: Raakvlak, BR86/SPIE-SPR/1/1/A/26\n",
      "Q102129228: slate in stone -- slate in stone, late Middle Ages/early modern period, location of discovery: Bruges, collection: Raakvlak, BR83/ANN/1/1/A/3\n",
      "Q102129246: rosary in amber -- rosary in amber, late Middle Ages, location of discovery: Bruges, collection: Raakvlak, BR84-85/RP/7\n",
      "Q102129286: fire grate in red earthenware -- fire grate in red earthenware, early modern period, location of discovery: Bruges, collection: Raakvlak, BR14/EZ/1/4/A/139\n",
      "Q107439832: cooking jug in red earthenware -- cooking jug in red earthenware, late Middle Ages, location of discovery: Bruges, collection: Raakvlak, 93008/1/10A/A/11\n",
      "Q107439856: thimble in copper -- thimble in copper, late Middle Ages, location of discovery: Bruges, collection: Raakvlak, BR12/JS/1/2/A/1143\n",
      "Q107439878: jar in grey earthenware -- jar in grey earthenware, late Middle Ages, location of discovery: Bruges, collection: Raakvlak, BR88/PSK/E/1\n",
      "Q107439894: jar in red earthenware -- jar in red earthenware, late Middle Ages, location of discovery: Bruges, collection: Raakvlak, BR88/PSK/E/41\n",
      "Q107439895: jar in red earthenware -- jar in red earthenware, late Middle Ages, location of discovery: Bruges, collection: Raakvlak, BR88/PSK/E/46\n",
      "Q99527133: plate in ceramic -- plate in ceramic, early modern period, location of discovery: Bruges, collection: Raakvlak, BR14/EZ/1/4/A/289\n",
      "Q99527194: plate in ceramic -- plate in ceramic, early modern period, location of discovery: Bruges, collection: Raakvlak, 92007/1/3/108 a\n",
      "Q99527195: plate in ceramic -- plate in ceramic, early modern period, location of discovery: Bruges, collection: Raakvlak, 92007/1/3/108 b\n",
      "Q99527197: plate in ceramic -- plate in ceramic, early modern period, location of discovery: Bruges, collection: Raakvlak, 92007/1/3/108d\n",
      "Q99527200: plate in ceramic -- plate in ceramic, early modern period, location of discovery: Bruges, collection: Raakvlak, 92007/1/3/116\n",
      "Q99527210: plate in ceramic -- plate in ceramic, early modern period, location of discovery: Bruges, collection: Raakvlak, 92007/1/3/126\n",
      "Q99527211: plate in faience -- plate in faience, early modern period, location of discovery: Bruges, collection: Raakvlak, BR90/WI/1/55/14\n",
      "Q99527224: plate in faience -- plate in faience, early modern period, location of discovery: Bruges, collection: Raakvlak, 93007/1/10/A/1\n",
      "Q19176563: Die Indianer beim Lachsfang -- German article in Die Gartenlaube, 1865, no. 48\n"
     ]
    }
   ],
   "source": [
    "idx = 69\n",
    "print(eval_data[idx]['entities']['query'].keys())\n",
    "print(eval_data[idx]['relations']['query'].keys())\n",
    "print('======')\n",
    "print(batch_file[idx]['body']['messages'][1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "71fbbff5-8895-4a55-ac3d-ca572edbabec",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'{data_name}_{task_name}_{topk}.jsonl')\n",
    "\n",
    "if not os.path.exists(os.path.dirname(batch_file_path)):\n",
    "    os.makedirs(os.path.dirname(batch_file_path))\n",
    "\n",
    "with open(batch_file_path, 'w') as jsonl_file:\n",
    "    for entry in batch_file:\n",
    "        jsonl_file.write(json.dumps(entry) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "976627f6-08fc-44cd-b8eb-ced16883fcb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_response = ask_openai_batch(batch_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "59fbbd5b-1dc2-4886-989a-7952c8f3b9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_67d40bb8a3088190a1efb5ea07bd70ac', completion_window='24h', created_at=1741949880, endpoint='/v1/chat/completions', input_file_id='file-6GfyrKnkWnutYNhUQayAhF', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1742036280, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ac8d0b-e27d-4872-bdf6-b1cfe73a0804",
   "metadata": {},
   "source": [
    "## gpt-4-1106-preview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d3c605-4a2c-4cc8-a900-3f83aec41dc9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Rubq Entity 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "bdd21718-1473-4d54-9af0-4baf8607f0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('completed', BatchRequestCounts(completed=479, failed=0, total=479))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_ = 'batch_67c8cd0d2808819088783fa5f60e8285'\n",
    "check_batch(id_).status, check_batch(id_).request_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "18f608d5-eceb-4ab0-9717-78449c69f83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.5997448387845049\n",
      "Recall:  0.6256089074460681\n",
      "F1:  0.6015243397289326\n"
     ]
    }
   ],
   "source": [
    "out_id_ = check_batch(id_).output_file_id\n",
    "response_list = get_response_batch(out_id_)\n",
    "result = get_result(eval_data, retriver_out, response_list, search_pattern=task_name)\n",
    "get_metrics(eval_data, response_list, search_pattern=task_name, gold_key=retr_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e515339b-07c2-45ea-b3a2-1ffee3265659",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'{data_name}_result_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(result, open(result_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "51ac4695-556b-4840-a752-b195570a017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'response_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(response_list, open(response_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e9c3ae07-8ac5-4cbb-8699-9cf4a283edbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage = {'prompt_tokens': 1789258, 'completion_tokens': 48322}\n",
      "price = 9.67$\n"
     ]
    }
   ],
   "source": [
    "usage = get_usage_info(id_)\n",
    "print(\n",
    "    f\"usage = {usage}\",\n",
    "    f\"price = {round(price_per_1m['prompt'] * usage['prompt_tokens']/1e6 + price_per_1m['completion'] * usage['completion_tokens']/1e6, 2)}$\",\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64acf6d-ba38-4686-9e2f-36ff8fc0049d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Rubq Entity 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "97cd50b1-0d41-4c10-bb3d-d3c1d66dda13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('completed', BatchRequestCounts(completed=479, failed=0, total=479))"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_ = 'batch_67c8d69d880481908a7a56d38a85445c'\n",
    "check_batch(id_).status, check_batch(id_).request_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2d46be2c-6ec7-40a8-8001-75158365f173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.5207111376213673\n",
      "Recall:  0.5511482254697286\n",
      "F1:  0.5258342446233887\n"
     ]
    }
   ],
   "source": [
    "out_id_ = check_batch(id_).output_file_id\n",
    "response_list = get_response_batch(out_id_)\n",
    "result = get_result(eval_data, retriver_out, response_list, search_pattern=task_name)\n",
    "get_metrics(eval_data, response_list, search_pattern=task_name, gold_key=retr_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "aab83db2-9b10-4ea0-9aa4-0b01c4be9fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'{data_name}_result_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(result, open(result_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "1e86695c-43eb-4bb9-9f3c-33f15dd37921",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'response_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(response_list, open(response_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "43442f86-fe97-4eaa-a6e4-3275f2e5f86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage = {'prompt_tokens': 651320, 'completion_tokens': 47531}\n",
      "price = 3.97$\n"
     ]
    }
   ],
   "source": [
    "usage = get_usage_info(id_)\n",
    "print(\n",
    "    f\"usage = {usage}\",\n",
    "    f\"price = {round(price_per_1m['prompt'] * usage['prompt_tokens']/1e6 + price_per_1m['completion'] * usage['completion_tokens']/1e6, 2)}$\",\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746063d6-e819-4910-9100-4a66fa34d564",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Rubq Property 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6b15df54-a10d-4070-961b-771b330b0dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('completed', BatchRequestCounts(completed=474, failed=0, total=474))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_ = 'batch_67c8dc8911a48190853a7856a5936e84'\n",
    "check_batch(id_).status, check_batch(id_).request_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "176548fb-7a15-4e9e-a8bc-96905ac532e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.7297669278681936\n",
      "Recall:  0.7626582278481012\n",
      "F1:  0.7283453887884268\n"
     ]
    }
   ],
   "source": [
    "out_id_ = check_batch(id_).output_file_id\n",
    "response_list = get_response_batch(out_id_)\n",
    "result = get_result(eval_data, retriver_out, response_list, search_pattern=task_name)\n",
    "get_metrics(eval_data, response_list, search_pattern=task_name, gold_key=retr_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b61064c7-ad87-4d9c-9480-02e5b3a0179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'{data_name}_result_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(result, open(result_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f82ee7d1-4f1e-4ea4-af76-a6066386deb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'response_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(response_list, open(response_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f62296ca-a81b-4d07-9723-caa8edbab929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage = {'prompt_tokens': 2341091, 'completion_tokens': 59164}\n",
      "price = 12.59$\n"
     ]
    }
   ],
   "source": [
    "usage = get_usage_info(id_)\n",
    "print(\n",
    "    f\"usage = {usage}\",\n",
    "    f\"price = {round(price_per_1m['prompt'] * usage['prompt_tokens']/1e6 + price_per_1m['completion'] * usage['completion_tokens']/1e6, 2)}$\",\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e868751e-17f5-41f2-81b0-9749cfd223cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Rubq Property 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f530be92-2604-4104-bcc0-93706f3ddc6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('completed', BatchRequestCounts(completed=474, failed=0, total=474))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_ = 'batch_67c8e18605988190af52f49d7747c0fc'\n",
    "check_batch(id_).status, check_batch(id_).request_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "bb35a2f8-b9cc-4771-b482-9a0064ee23d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.7324191279887483\n",
      "Recall:  0.7563291139240507\n",
      "F1:  0.7312939521800285\n"
     ]
    }
   ],
   "source": [
    "out_id_ = check_batch(id_).output_file_id\n",
    "response_list = get_response_batch(out_id_)\n",
    "result = get_result(eval_data, retriver_out, response_list, search_pattern=task_name)\n",
    "get_metrics(eval_data, response_list, search_pattern=task_name, gold_key=retr_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f4c998ac-f68e-435f-b857-6e9533cdf333",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'{data_name}_result_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(result, open(result_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "166f8385-60b0-456f-9a7a-ae33189ff7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'response_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(response_list, open(response_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0cf3e20c-e11c-4e73-8a33-4224fb916884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage = {'prompt_tokens': 1122868, 'completion_tokens': 55037}\n",
      "price = 6.44$\n"
     ]
    }
   ],
   "source": [
    "usage = get_usage_info(id_)\n",
    "print(\n",
    "    f\"usage = {usage}\",\n",
    "    f\"price = {round(price_per_1m['prompt'] * usage['prompt_tokens']/1e6 + price_per_1m['completion'] * usage['completion_tokens']/1e6, 2)}$\",\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f498661e-3907-45f1-a4c9-a87a85bd03a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Lcquad Entity 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "72e02c3b-0cbc-4ec1-83af-d346b145144f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('completed', BatchRequestCounts(completed=4540, failed=0, total=4540))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_ = 'batch_67c8e547658481908cb0ab9d2126a95b'\n",
    "check_batch(id_).status, check_batch(id_).request_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "641dbe94-2f8f-40ba-a41e-446bdb6eb2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.5937634780815261\n",
      "Recall:  0.5361600587371511\n",
      "F1:  0.5413891375925214\n"
     ]
    }
   ],
   "source": [
    "out_id_ = check_batch(id_).output_file_id\n",
    "response_list = get_response_batch(out_id_)\n",
    "result = get_result(eval_data, retriver_out, response_list, search_pattern=task_name)\n",
    "get_metrics(eval_data, response_list, search_pattern=task_name, gold_key=retr_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "67051040-e82f-4de9-aa63-bc0d0f0ad9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'{data_name}_result_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(result, open(result_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d2fd6ba4-1105-4db0-9d3a-31cbfe018d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'response_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(response_list, open(response_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "dc64d7bd-2f45-4a68-b9a1-9c5ed0821269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage = {'prompt_tokens': 16954379, 'completion_tokens': 570771}\n",
      "price = 93.33$\n"
     ]
    }
   ],
   "source": [
    "usage = get_usage_info(id_)\n",
    "print(\n",
    "    f\"usage = {usage}\",\n",
    "    f\"price = {round(price_per_1m['prompt'] * usage['prompt_tokens']/1e6 + price_per_1m['completion'] * usage['completion_tokens']/1e6, 2)}$\",\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983815b2-f109-4562-8cd0-da7c88fb4400",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Lcquad Entity 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "47a04319-f88e-4fae-8d4d-ef6e1ed2e946",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('completed', BatchRequestCounts(completed=4540, failed=0, total=4540))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_ = 'batch_67c8ec2b8dcc8190b64f039cc0fdf2a5'\n",
    "check_batch(id_).status, check_batch(id_).request_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "869c9b4d-0539-4087-8105-30aec4c2a76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.5292405251381022\n",
      "Recall:  0.4805066079295155\n",
      "F1:  0.4865486997094956\n"
     ]
    }
   ],
   "source": [
    "out_id_ = check_batch(id_).output_file_id\n",
    "response_list = get_response_batch(out_id_)\n",
    "result = get_result(eval_data, retriver_out, response_list, search_pattern=task_name)\n",
    "get_metrics(eval_data, response_list, search_pattern=task_name, gold_key=retr_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "05676dcf-94ee-4376-93b6-033d2411cad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'{data_name}_result_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(result, open(result_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d2630be7-9b10-40dc-aa01-3402a44057a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'response_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(response_list, open(response_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a2673228-449a-4569-a447-cd53f5a90199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage = {'prompt_tokens': 6182021, 'completion_tokens': 509800}\n",
      "price = 38.56$\n"
     ]
    }
   ],
   "source": [
    "usage = get_usage_info(id_)\n",
    "print(\n",
    "    f\"usage = {usage}\",\n",
    "    f\"price = {round(price_per_1m['prompt'] * usage['prompt_tokens']/1e6 + price_per_1m['completion'] * usage['completion_tokens']/1e6, 2)}$\",\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32481fd-6e83-4729-b470-07636d51661b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Lcquad Property 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e09ff08b-e17e-4c9f-b089-63c299fccf7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('completed', BatchRequestCounts(completed=4541, failed=0, total=4541))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_ = 'batch_67c9879c57088190a4e013e99451a318'\n",
    "check_batch(id_).status, check_batch(id_).request_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b3f8f997-36d8-4649-a60a-4c29f41cd60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.7227689167129817\n",
      "Recall:  0.608199368714674\n",
      "F1:  0.6294626352873383\n"
     ]
    }
   ],
   "source": [
    "out_id_ = check_batch(id_).output_file_id\n",
    "response_list = get_response_batch(out_id_)\n",
    "result = get_result(eval_data, retriver_out, response_list, search_pattern=task_name)\n",
    "get_metrics(eval_data, response_list, search_pattern=task_name, gold_key=retr_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cfd7d180-46ca-46ba-b1a5-31b9a09fc48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'{data_name}_result_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(result, open(result_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "cdd98fa5-d9cf-4afe-9312-5adbcd6d63ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'response_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(response_list, open(response_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e519c34d-2bd2-4dc6-87fe-eafce271c58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage = {'prompt_tokens': 22346997, 'completion_tokens': 678813}\n",
      "price = 121.92$\n"
     ]
    }
   ],
   "source": [
    "usage = get_usage_info(id_)\n",
    "print(\n",
    "    f\"usage = {usage}\",\n",
    "    f\"price = {round(price_per_1m['prompt'] * usage['prompt_tokens']/1e6 + price_per_1m['completion'] * usage['completion_tokens']/1e6, 2)}$\",\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51af1a91-4664-4eed-831c-32592a5e9cd3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Lcquad Property 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "dbe3352f-aea5-4f2d-8341-025beb60421b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('completed', BatchRequestCounts(completed=4541, failed=0, total=4541))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_ = 'batch_67c9925f48d4819095e49188abb1eccd'\n",
    "check_batch(id_).status, check_batch(id_).request_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "abb7241e-3ae6-43af-b1ef-52c5b1ade68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.7320597518901855\n",
      "Recall:  0.5993540336196135\n",
      "F1:  0.6343499963297295\n"
     ]
    }
   ],
   "source": [
    "out_id_ = check_batch(id_).output_file_id\n",
    "response_list = get_response_batch(out_id_)\n",
    "result = get_result(eval_data, retriver_out, response_list, search_pattern=task_name)\n",
    "get_metrics(eval_data, response_list, search_pattern=task_name, gold_key=retr_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "63fa614f-0705-445d-9144-c674ae487b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'{data_name}_result_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(result, open(result_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0cc1dc5f-193a-421c-bbb7-b876fdc5a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'response_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(response_list, open(response_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7415059a-f5b3-4432-bbec-35d21a878ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage = {'prompt_tokens': 10758067, 'completion_tokens': 651753}\n",
      "price = 63.57$\n"
     ]
    }
   ],
   "source": [
    "usage = get_usage_info(id_)\n",
    "print(\n",
    "    f\"usage = {usage}\",\n",
    "    f\"price = {round(price_per_1m['prompt'] * usage['prompt_tokens']/1e6 + price_per_1m['completion'] * usage['completion_tokens']/1e6, 2)}$\",\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238cbeee-77f2-4bdd-8a61-e4445b161812",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Pat Entity 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5ccdd338-2faf-47a4-abce-96041a867807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('completed', BatchRequestCounts(completed=1199, failed=0, total=1199))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_ = 'batch_67c9a4b588ec8190b5482f5e69e83e39'\n",
    "check_batch(id_).status, check_batch(id_).request_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1d4845b4-2f5b-4085-aeca-31fe9f6bafa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.44856825132054484\n",
      "Recall:  0.45287739783152625\n",
      "F1:  0.4499582985821518\n"
     ]
    }
   ],
   "source": [
    "out_id_ = check_batch(id_).output_file_id\n",
    "response_list = get_response_batch(out_id_)\n",
    "result = get_result(eval_data, retriver_out, response_list, search_pattern=task_name)\n",
    "get_metrics(eval_data, response_list, search_pattern=task_name, gold_key=retr_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d8ab46ac-906a-45c0-bec0-970c5fb8e8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'{data_name}_result_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(result, open(result_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e2ead09d-30c4-47bc-a476-9bb6c3e77c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'response_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(response_list, open(response_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "fee5c6f5-6eb9-431e-a189-fc5b326d6f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage = {'prompt_tokens': 3993032, 'completion_tokens': 139411}\n",
      "price = 22.06$\n"
     ]
    }
   ],
   "source": [
    "usage = get_usage_info(id_)\n",
    "print(\n",
    "    f\"usage = {usage}\",\n",
    "    f\"price = {round(price_per_1m['prompt'] * usage['prompt_tokens']/1e6 + price_per_1m['completion'] * usage['completion_tokens']/1e6, 2)}$\",\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22312c58-04c4-4efb-a823-884d43115cf2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Pat Entity 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "52cd90a6-cc18-40f1-9f61-20947020eebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('completed', BatchRequestCounts(completed=1199, failed=0, total=1199))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_ = 'batch_67cac8421b148190af92580078ea6f20'\n",
    "check_batch(id_).status, check_batch(id_).request_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a519f643-c974-4672-81f9-c28592d59ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.4359883236030025\n",
      "Recall:  0.44286905754795663\n",
      "F1:  0.43819849874895755\n"
     ]
    }
   ],
   "source": [
    "out_id_ = check_batch(id_).output_file_id\n",
    "response_list = get_response_batch(out_id_)\n",
    "result = get_result(eval_data, retriver_out, response_list, search_pattern=task_name)\n",
    "get_metrics(eval_data, response_list, search_pattern=task_name, gold_key=retr_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9ad8bc59-f217-45b7-b98b-83504500965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'{data_name}_result_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(result, open(result_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2fdd8094-ce9d-4568-9104-00aa06eb9083",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'response_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(response_list, open(response_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "18cc8674-fd8d-4269-a8bf-1c82880a0000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage = {'prompt_tokens': 1605520, 'completion_tokens': 128690}\n",
      "price = 9.96$\n"
     ]
    }
   ],
   "source": [
    "usage = get_usage_info(id_)\n",
    "print(\n",
    "    f\"usage = {usage}\",\n",
    "    f\"price = {round(price_per_1m['prompt'] * usage['prompt_tokens']/1e6 + price_per_1m['completion'] * usage['completion_tokens']/1e6, 2)}$\",\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376a6efb-e765-4f33-9439-b96990144507",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Pat Property 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0bad9a72-5cc1-429f-9fb9-01dc6e0529b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('completed', BatchRequestCounts(completed=1199, failed=0, total=1199))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_ = 'batch_67d2d7dfea508190b5fc8e2c74c1513f'\n",
    "check_batch(id_).status, check_batch(id_).request_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "26dd0292-b03e-4e0b-85cd-a8757603e2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.6513622463163748\n",
      "Recall:  0.25604670558799014\n",
      "F1:  0.35431642771092237\n"
     ]
    }
   ],
   "source": [
    "out_id_ = check_batch(id_).output_file_id\n",
    "response_list = get_response_batch(out_id_)\n",
    "result = get_result(eval_data, retriver_out, response_list, search_pattern=task_name)\n",
    "get_metrics(eval_data, response_list, search_pattern=task_name, gold_key=retr_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bdd44aa2-8878-4fcb-a3b6-8cbd11c734cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'{data_name}_result_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(result, open(result_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "75685172-57fe-4c7a-8473-a238d27b7fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'response_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(response_list, open(response_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e17890f7-a00c-42a1-ab92-99f6f7417ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage = {'prompt_tokens': 5934881, 'completion_tokens': 174872}\n",
      "price = 32.3$\n"
     ]
    }
   ],
   "source": [
    "usage = get_usage_info(id_)\n",
    "print(\n",
    "    f\"usage = {usage}\",\n",
    "    f\"price = {round(price_per_1m['prompt'] * usage['prompt_tokens']/1e6 + price_per_1m['completion'] * usage['completion_tokens']/1e6, 2)}$\",\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353a38bf-d7a4-48de-b784-7825d99d7437",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Pat Property 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cdef0ab7-1382-4bae-880f-d4ad7e7ae5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('completed', BatchRequestCounts(completed=1199, failed=0, total=1199))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_ = 'batch_67d2f1cba2dc819095224c4246eb1436'\n",
    "check_batch(id_).status, check_batch(id_).request_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cf507310-95b2-49a3-a27b-8bb095c9d29d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.7322073950514317\n",
      "Recall:  0.2970530998053915\n",
      "F1:  0.41236347750109015\n"
     ]
    }
   ],
   "source": [
    "out_id_ = check_batch(id_).output_file_id\n",
    "response_list = get_response_batch(out_id_)\n",
    "result = get_result(eval_data, retriver_out, response_list, search_pattern=task_name)\n",
    "get_metrics(eval_data, response_list, search_pattern=task_name, gold_key=retr_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d0166d73-cec5-4014-a9c0-b4a6d1ce995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'{data_name}_result_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(result, open(result_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "205f8da4-da41-42c3-acc0-a1a6f67feb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'response_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(response_list, open(response_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8a8496b8-62e4-49d7-be94-cc5b18090f54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage = {'prompt_tokens': 2787812, 'completion_tokens': 149742}\n",
      "price = 16.19$\n"
     ]
    }
   ],
   "source": [
    "usage = get_usage_info(id_)\n",
    "print(\n",
    "    f\"usage = {usage}\",\n",
    "    f\"price = {round(price_per_1m['prompt'] * usage['prompt_tokens']/1e6 + price_per_1m['completion'] * usage['completion_tokens']/1e6, 2)}$\",\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea0a4a2-9ddb-4bd0-a2c1-b8bc20ef0111",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Qald Entity 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5b73a12c-d4e7-4fa3-a3cd-86340a41ce7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('completed', BatchRequestCounts(completed=386, failed=0, total=386))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_ = 'batch_67d3ffc087488190bd4a5b1b2b9e774c'\n",
    "check_batch(id_).status, check_batch(id_).request_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c198164-3d6c-4c67-88e2-571d0d1deec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.6102208240809276\n",
      "Recall:  0.5256908462867014\n",
      "F1:  0.5385635126243932\n"
     ]
    }
   ],
   "source": [
    "out_id_ = check_batch(id_).output_file_id\n",
    "response_list = get_response_batch(out_id_)\n",
    "result = get_result(eval_data, retriver_out, response_list, search_pattern=task_name)\n",
    "get_metrics(eval_data, response_list, search_pattern=task_name, gold_key=retr_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78e86a9a-3138-4c5d-b8c5-8170d4e70c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'{data_name}_result_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(result, open(result_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d31ab05-64c0-4f29-af02-ae39db5098c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'response_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(response_list, open(response_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0b961600-0a31-4b6f-a629-b64f8c8a71b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage = {'prompt_tokens': 1434749, 'completion_tokens': 44114}\n",
      "price = 7.84$\n"
     ]
    }
   ],
   "source": [
    "usage = get_usage_info(id_)\n",
    "print(\n",
    "    f\"usage = {usage}\",\n",
    "    f\"price = {round(price_per_1m['prompt'] * usage['prompt_tokens']/1e6 + price_per_1m['completion'] * usage['completion_tokens']/1e6, 2)}$\",\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cdfc7b-dfcf-4aac-9ac7-e7a9821376ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Qald Entity 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cb9d35db-a5eb-4a4e-b260-aed931c4bee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('completed', BatchRequestCounts(completed=386, failed=0, total=386))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_ = 'batch_67d4060f338c8190958d3167191e71d7'\n",
    "check_batch(id_).status, check_batch(id_).request_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8833ef0c-9637-47f0-b8bd-f97d8ca3a506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.5639464594127805\n",
      "Recall:  0.4844559585492228\n",
      "F1:  0.5057101361505504\n"
     ]
    }
   ],
   "source": [
    "out_id_ = check_batch(id_).output_file_id\n",
    "response_list = get_response_batch(out_id_)\n",
    "result = get_result(eval_data, retriver_out, response_list, search_pattern=task_name)\n",
    "get_metrics(eval_data, response_list, search_pattern=task_name, gold_key=retr_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ff78034-d15f-48b0-a573-5679841f747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'{data_name}_result_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(result, open(result_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f967129-a81a-4275-b654-cf0d5c463f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'response_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(response_list, open(response_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "926e02ee-0493-4bf9-8e82-d439d66547e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage = {'prompt_tokens': 522706, 'completion_tokens': 39543}\n",
      "price = 3.21$\n"
     ]
    }
   ],
   "source": [
    "usage = get_usage_info(id_)\n",
    "print(\n",
    "    f\"usage = {usage}\",\n",
    "    f\"price = {round(price_per_1m['prompt'] * usage['prompt_tokens']/1e6 + price_per_1m['completion'] * usage['completion_tokens']/1e6, 2)}$\",\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1576d3f-fe4a-4402-939b-b8ca8699b683",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Qald Property 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7b26e783-5078-4b25-8731-80011a2b6b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('completed', BatchRequestCounts(completed=384, failed=0, total=384))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_ = 'batch_67d409fd2fb08190864a022ee64f685d'\n",
    "check_batch(id_).status, check_batch(id_).request_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d14ff756-643b-4d6f-aa10-f1100ccb4e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.7109809027777777\n",
      "Recall:  0.6230468749999999\n",
      "F1:  0.6288917824074071\n"
     ]
    }
   ],
   "source": [
    "out_id_ = check_batch(id_).output_file_id\n",
    "response_list = get_response_batch(out_id_)\n",
    "result = get_result(eval_data, retriver_out, response_list, search_pattern=task_name)\n",
    "get_metrics(eval_data, response_list, search_pattern=task_name, gold_key=retr_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "196215f6-9d11-49b3-bbf2-3bab91598718",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'{data_name}_result_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(result, open(result_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "000c075c-1f78-4664-8d54-fbd05db9db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'response_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(response_list, open(response_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "607858a2-4ff2-4db2-97ac-168fff3a4637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage = {'prompt_tokens': 1905308, 'completion_tokens': 55194}\n",
      "price = 10.35$\n"
     ]
    }
   ],
   "source": [
    "usage = get_usage_info(id_)\n",
    "print(\n",
    "    f\"usage = {usage}\",\n",
    "    f\"price = {round(price_per_1m['prompt'] * usage['prompt_tokens']/1e6 + price_per_1m['completion'] * usage['completion_tokens']/1e6, 2)}$\",\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29d2db2-5fb2-465e-8587-645a4261f1b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Qald Property 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "389eac20-23ad-48fb-992a-ce40b1b7e786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('completed', BatchRequestCounts(completed=384, failed=0, total=384))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_ = 'batch_67d40bb8a3088190a1efb5ea07bd70ac'\n",
    "check_batch(id_).status, check_batch(id_).request_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cbf65bbd-75d8-49fc-a2d0-363dd51b6030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.683376736111111\n",
      "Recall:  0.5577256944444444\n",
      "F1:  0.5875124007936506\n"
     ]
    }
   ],
   "source": [
    "out_id_ = check_batch(id_).output_file_id\n",
    "response_list = get_response_batch(out_id_)\n",
    "result = get_result(eval_data, retriver_out, response_list, search_pattern=task_name)\n",
    "get_metrics(eval_data, response_list, search_pattern=task_name, gold_key=retr_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf1c205b-2075-4b33-ba76-8c46c2520b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'{data_name}_result_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(result, open(result_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36b701cd-67ff-4c7f-8bd6-fd9e544fc5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_file_path = os.path.join(os.path.dirname(retriver_out_path), \"gpt-4-1106-preview\",\n",
    "                               f'response_{task_name}_{topk}.jsonl')\n",
    "\n",
    "json.dump(response_list, open(response_file_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "be96f3ff-4ad3-420c-8d38-f033643b451b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage = {'prompt_tokens': 910185, 'completion_tokens': 53658}\n",
      "price = 5.36$\n"
     ]
    }
   ],
   "source": [
    "usage = get_usage_info(id_)\n",
    "print(\n",
    "    f\"usage = {usage}\",\n",
    "    f\"price = {round(price_per_1m['prompt'] * usage['prompt_tokens']/1e6 + price_per_1m['completion'] * usage['completion_tokens']/1e6, 2)}$\",\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d96c5-dd56-4a8c-ab24-6567cb0ec1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e100c547-5cf4-400d-b238-3beb4bbbca81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eed51e-925e-42cc-93a9-240fc93b0ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b825e7-2e92-4cb3-90cc-0fef68a8aac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d93a952-731b-46fe-91e2-60743f5656cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270f3ed5-6072-43ca-be14-7e76f6b1c643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949d2bf-3abb-4a2b-b2b1-204c1e400904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5dae73-3d31-4ce6-9964-36046aacfdc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6b8abf-50e3-481b-b329-c017b14fee55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb6a849-8b9a-42e3-87df-9242d01bd8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8113f7ae-92ac-4dc2-aa0f-7db96dcb68ae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## get error file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4551503f-c84f-4ae5-914d-1e8109dc4072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc622a1-4abe-4ccc-82d6-06ebbfbe46da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a72455-d553-4caf-b0fa-40e23ee39648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca325c09-210b-4f7f-a108-63ba43e47dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6516b3dc-f5dd-420b-af7c-0ec04ac612ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa7668e-9fe5-4283-b656-fceaff3e7a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bb94d7-23e6-45d0-8c5e-f4500ead7544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe16bdd-a8f8-4407-a9d8-5d9de231acfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed0d62e-0d71-4615-930f-a9ea1bc8afa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a3eeaa-20ce-4807-9fa1-c0d8219de2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43330aa6-9710-4914-b63b-863fe66eaef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22120744-cf30-4d49-b3d9-a48da94d51ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cf015c1c-fd4e-439e-a0c8-119a9ba6b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_KEY\"),\n",
    ")\n",
    "file_response = client.files.content(check_batch('batch_67cacfcc55cc81909fae43bfc1f4fe2c').error_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c5a64516-6684-4c9b-bd11-6eb6a4a1981d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\": \"batch_req_67cad4c2ed648190a7c2db6ae406883a\", \"custom_id\": \"request_32\", \"response\": {\"status_code\": 429, \"request_id\": \"49e94329ca3590edcb57443f136b0c00\", \"body\": {\"error\": {\"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\", \"type\": \"insufficient_quota\", \"param\": null, \"code\": \"insufficient_quota\"}}}, \"error\": null}\\n{\"id\": \"batch_req_67cad4cbc730819097373e4d33c1b755\", \"custom_id\": \"request_147\", \"response\": {\"status_code\": 429, \"request_id\": \"d1c7c1ac87ff143e5cca484c9f76779e\", \"body\": {\"error\": {\"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\", \"type\": \"insufficient_quota\", \"param\": null, \"code\": \"insufficient_quota\"}}}, \"error\": null}\\n{\"id\": \"batch_req_67cad4d880188190af505a2e6d0d9c9f\", \"custom_id\": \"request_318\", \"response\": {\"status_code\": 429, \"request_id\": \"8d36f1653f67f797d6b36ba67110cac5\", \"body\": {\"error\": {\"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\", \"type\": \"insufficient_quota\", \"param\": null, \"code\": \"insufficient_quota\"}}}, \"error\": null}\\n{\"id\": \"batch_req_67cad4d890c48190a06d32f24f11cdee\", \"custom_id\": \"request_319\", \"response\": {\"status_code\": 429, \"request_id\": \"9d8b667431f77fe582b83bf9402ba6d0\", \"body\": {\"error\": {\"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\", \"type\": \"insufficient_quota\", \"param\": null, \"code\": \"insufficient_quota\"}}}, \"error\": null}\\n{\"id\": \"batch_req_67cad4e91bac81909a75b3c67ed18777\", \"custom_id\": \"request_538\", \"response\": {\"status_code\": 429, \"request_id\": \"62ceed2d05ad165d5ffb4dad4aaa46fb\", \"body\": {\"error\": {\"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\", \"type\": \"insufficient_quota\", \"param\": null, \"code\": \"insufficient_quota\"}}}, \"error\": null}\\n{\"id\": \"batch_req_67cad4f2d7a481908d559004b75b93df\", \"custom_id\": \"request_668\", \"response\": {\"status_code\": 429, \"request_id\": \"74d9f0049c3615d98aad48f5e6843e89\", \"body\": {\"error\": {\"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\", \"type\": \"insufficient_quota\", \"param\": null, \"code\": \"insufficient_quota\"}}}, \"error\": null}\\n{\"id\": \"batch_req_67cad4f54c7c819086781a7ab14daae2\", \"custom_id\": \"request_699\", \"response\": {\"status_code\": 429, \"request_id\": \"85a254f64751f94cf0ebf4d1cf45ae29\", \"body\": {\"error\": {\"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\", \"type\": \"insufficient_quota\", \"param\": null, \"code\": \"insufficient_quota\"}}}, \"error\": null}\\n{\"id\": \"batch_req_67cad4f6784481909d763189e256880b\", \"custom_id\": \"request_714\", \"response\": {\"status_code\": 429, \"request_id\": \"cc563be55e3f4b43b77c1f47576d8a7f\", \"body\": {\"error\": {\"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\", \"type\": \"insufficient_quota\", \"param\": null, \"code\": \"insufficient_quota\"}}}, \"error\": null}\\n{\"id\": \"batch_req_67cad507340c8190bbdec9aa628d44f2\", \"custom_id\": \"request_926\", \"response\": {\"status_code\": 429, \"request_id\": \"408109dc162578c541365e03860a7345\", \"body\": {\"error\": {\"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\", \"type\": \"insufficient_quota\", \"param\": null, \"code\": \"insufficient_quota\"}}}, \"error\": null}\\n{\"id\": \"batch_req_67cad507458481908e6c1f7c40c8e274\", \"custom_id\": \"request_927\", \"response\": {\"status_code\": 429, \"request_id\": \"15c96f1f5db8dd7d0049744814188887\", \"body\": {\"error\": {\"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\", \"type\": \"insufficient_quota\", \"param\": null, \"code\": \"insufficient_quota\"}}}, \"error\": null}\\n{\"id\": \"batch_req_67cad507951c8190a85e4cc7b8bd5df0\", \"custom_id\": \"request_931\", \"response\": {\"status_code\": 429, \"request_id\": \"fa243aa2bb48d4bf2a03132c5cc73801\", \"body\": {\"error\": {\"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\", \"type\": \"insufficient_quota\", \"param\": null, \"code\": \"insufficient_quota\"}}}, \"error\": null}\\n{\"id\": \"batch_req_67cad50cc74081909db0d61531db02b1\", \"custom_id\": \"request_998\", \"response\": {\"status_code\": 429, \"request_id\": \"b9607b6ec29b202af237c08ac275e5f7\", \"body\": {\"error\": {\"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\", \"type\": \"insufficient_quota\", \"param\": null, \"code\": \"insufficient_quota\"}}}, \"error\": null}\\n{\"id\": \"batch_req_67cad51aae3c8190bc7cda2c3a6bf59c\", \"custom_id\": \"request_1175\", \"response\": {\"status_code\": 429, \"request_id\": \"383625f06cfa9142f6f28d0980af8e28\", \"body\": {\"error\": {\"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\", \"type\": \"insufficient_quota\", \"param\": null, \"code\": \"insufficient_quota\"}}}, \"error\": null}\\n{\"id\": \"batch_req_67cad51aefd081908742e8ecb032573f\", \"custom_id\": \"request_1178\", \"response\": {\"status_code\": 429, \"request_id\": \"d4ec61f8a96e2aa8f6af9471c75eddec\", \"body\": {\"error\": {\"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\", \"type\": \"insufficient_quota\", \"param\": null, \"code\": \"insufficient_quota\"}}}, \"error\": null}\\n{\"id\": \"batch_req_67cad51b14dc8190be28c6a2f871ec08\", \"custom_id\": \"request_1180\", \"response\": {\"status_code\": 429, \"request_id\": \"1a7974d039e8057bcd1fe80d34552b46\", \"body\": {\"error\": {\"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\", \"type\": \"insufficient_quota\", \"param\": null, \"code\": \"insufficient_quota\"}}}, \"error\": null}\\n{\"id\": \"batch_req_67cad51b50688190a14ec7beb165c5f5\", \"custom_id\": \"request_1183\", \"response\": {\"status_code\": 429, \"request_id\": \"76f5312bb192cdce24ac603600f92dec\", \"body\": {\"error\": {\"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\", \"type\": \"insufficient_quota\", \"param\": null, \"code\": \"insufficient_quota\"}}}, \"error\": null}\\n{\"id\": \"batch_req_67cad51b868c8190b5ee9e5c052ca1b4\", \"custom_id\": \"request_1186\", \"response\": {\"status_code\": 429, \"request_id\": \"81e7191127bfc672c19a470d5935d632\", \"body\": {\"error\": {\"message\": \"You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\", \"type\": \"insufficient_quota\", \"param\": null, \"code\": \"insufficient_quota\"}}}, \"error\": null}\\n'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4120097-4cf2-4069-9dc1-0647d165ce43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a36f434a-4842-439f-a560-5bc29ad4acbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "92089a00-adc3-4250-82e2-13c67fc27ae7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ConflictError",
     "evalue": "Error code: 409 - {'error': {'message': \"Cannot cancel a batch with status 'completed'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mConflictError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[90], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m client\u001B[38;5;241m.\u001B[39mbatches\u001B[38;5;241m.\u001B[39mcancel(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch_67cacfcc55cc81909fae43bfc1f4fe2c\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/miniconda3/envs/env_chatgptapi/lib/python3.13/site-packages/openai/resources/batches.py:226\u001B[0m, in \u001B[0;36mBatches.cancel\u001B[0;34m(self, batch_id, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    224\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m batch_id:\n\u001B[1;32m    225\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected a non-empty value for `batch_id` but received \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbatch_id\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 226\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post(\n\u001B[1;32m    227\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/batches/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbatch_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/cancel\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    228\u001B[0m     options\u001B[38;5;241m=\u001B[39mmake_request_options(\n\u001B[1;32m    229\u001B[0m         extra_headers\u001B[38;5;241m=\u001B[39mextra_headers, extra_query\u001B[38;5;241m=\u001B[39mextra_query, extra_body\u001B[38;5;241m=\u001B[39mextra_body, timeout\u001B[38;5;241m=\u001B[39mtimeout\n\u001B[1;32m    230\u001B[0m     ),\n\u001B[1;32m    231\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mBatch,\n\u001B[1;32m    232\u001B[0m )\n",
      "File \u001B[0;32m/opt/miniconda3/envs/env_chatgptapi/lib/python3.13/site-packages/openai/_base_client.py:1283\u001B[0m, in \u001B[0;36mSyncAPIClient.post\u001B[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1269\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpost\u001B[39m(\n\u001B[1;32m   1270\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1271\u001B[0m     path: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1278\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1279\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[1;32m   1280\u001B[0m     opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(\n\u001B[1;32m   1281\u001B[0m         method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpost\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, json_data\u001B[38;5;241m=\u001B[39mbody, files\u001B[38;5;241m=\u001B[39mto_httpx_files(files), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions\n\u001B[1;32m   1282\u001B[0m     )\n\u001B[0;32m-> 1283\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest(cast_to, opts, stream\u001B[38;5;241m=\u001B[39mstream, stream_cls\u001B[38;5;241m=\u001B[39mstream_cls))\n",
      "File \u001B[0;32m/opt/miniconda3/envs/env_chatgptapi/lib/python3.13/site-packages/openai/_base_client.py:960\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    957\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    958\u001B[0m     retries_taken \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 960\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request(\n\u001B[1;32m    961\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m    962\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[1;32m    963\u001B[0m     stream\u001B[38;5;241m=\u001B[39mstream,\n\u001B[1;32m    964\u001B[0m     stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[1;32m    965\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39mretries_taken,\n\u001B[1;32m    966\u001B[0m )\n",
      "File \u001B[0;32m/opt/miniconda3/envs/env_chatgptapi/lib/python3.13/site-packages/openai/_base_client.py:1049\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1047\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m remaining_retries \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_retry(err\u001B[38;5;241m.\u001B[39mresponse):\n\u001B[1;32m   1048\u001B[0m     err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m-> 1049\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retry_request(\n\u001B[1;32m   1050\u001B[0m         input_options,\n\u001B[1;32m   1051\u001B[0m         cast_to,\n\u001B[1;32m   1052\u001B[0m         retries_taken\u001B[38;5;241m=\u001B[39mretries_taken,\n\u001B[1;32m   1053\u001B[0m         response_headers\u001B[38;5;241m=\u001B[39merr\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mheaders,\n\u001B[1;32m   1054\u001B[0m         stream\u001B[38;5;241m=\u001B[39mstream,\n\u001B[1;32m   1055\u001B[0m         stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[1;32m   1056\u001B[0m     )\n\u001B[1;32m   1058\u001B[0m \u001B[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001B[39;00m\n\u001B[1;32m   1059\u001B[0m \u001B[38;5;66;03m# to completion before attempting to access the response text.\u001B[39;00m\n\u001B[1;32m   1060\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mis_closed:\n",
      "File \u001B[0;32m/opt/miniconda3/envs/env_chatgptapi/lib/python3.13/site-packages/openai/_base_client.py:1098\u001B[0m, in \u001B[0;36mSyncAPIClient._retry_request\u001B[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1094\u001B[0m \u001B[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001B[39;00m\n\u001B[1;32m   1095\u001B[0m \u001B[38;5;66;03m# different thread if necessary.\u001B[39;00m\n\u001B[1;32m   1096\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(timeout)\n\u001B[0;32m-> 1098\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request(\n\u001B[1;32m   1099\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[1;32m   1100\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m   1101\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39mretries_taken \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1102\u001B[0m     stream\u001B[38;5;241m=\u001B[39mstream,\n\u001B[1;32m   1103\u001B[0m     stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[1;32m   1104\u001B[0m )\n",
      "File \u001B[0;32m/opt/miniconda3/envs/env_chatgptapi/lib/python3.13/site-packages/openai/_base_client.py:1049\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1047\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m remaining_retries \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_retry(err\u001B[38;5;241m.\u001B[39mresponse):\n\u001B[1;32m   1048\u001B[0m     err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m-> 1049\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retry_request(\n\u001B[1;32m   1050\u001B[0m         input_options,\n\u001B[1;32m   1051\u001B[0m         cast_to,\n\u001B[1;32m   1052\u001B[0m         retries_taken\u001B[38;5;241m=\u001B[39mretries_taken,\n\u001B[1;32m   1053\u001B[0m         response_headers\u001B[38;5;241m=\u001B[39merr\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mheaders,\n\u001B[1;32m   1054\u001B[0m         stream\u001B[38;5;241m=\u001B[39mstream,\n\u001B[1;32m   1055\u001B[0m         stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[1;32m   1056\u001B[0m     )\n\u001B[1;32m   1058\u001B[0m \u001B[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001B[39;00m\n\u001B[1;32m   1059\u001B[0m \u001B[38;5;66;03m# to completion before attempting to access the response text.\u001B[39;00m\n\u001B[1;32m   1060\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mis_closed:\n",
      "File \u001B[0;32m/opt/miniconda3/envs/env_chatgptapi/lib/python3.13/site-packages/openai/_base_client.py:1098\u001B[0m, in \u001B[0;36mSyncAPIClient._retry_request\u001B[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1094\u001B[0m \u001B[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001B[39;00m\n\u001B[1;32m   1095\u001B[0m \u001B[38;5;66;03m# different thread if necessary.\u001B[39;00m\n\u001B[1;32m   1096\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(timeout)\n\u001B[0;32m-> 1098\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request(\n\u001B[1;32m   1099\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[1;32m   1100\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m   1101\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39mretries_taken \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1102\u001B[0m     stream\u001B[38;5;241m=\u001B[39mstream,\n\u001B[1;32m   1103\u001B[0m     stream_cls\u001B[38;5;241m=\u001B[39mstream_cls,\n\u001B[1;32m   1104\u001B[0m )\n",
      "File \u001B[0;32m/opt/miniconda3/envs/env_chatgptapi/lib/python3.13/site-packages/openai/_base_client.py:1064\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1061\u001B[0m         err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m   1063\u001B[0m     log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRe-raising status error\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1064\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1066\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_response(\n\u001B[1;32m   1067\u001B[0m     cast_to\u001B[38;5;241m=\u001B[39mcast_to,\n\u001B[1;32m   1068\u001B[0m     options\u001B[38;5;241m=\u001B[39moptions,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1072\u001B[0m     retries_taken\u001B[38;5;241m=\u001B[39mretries_taken,\n\u001B[1;32m   1073\u001B[0m )\n",
      "\u001B[0;31mConflictError\u001B[0m: Error code: 409 - {'error': {'message': \"Cannot cancel a batch with status 'completed'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "client.batches.cancel(\"batch_67cacfcc55cc81909fae43bfc1f4fe2c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ada5b9-ea8a-4500-9645-4ae4a1b48e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e850a-5488-4aa2-94fa-3b5c2913db92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30449ca-2c6e-4a80-b89e-1f617030c697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel_chatgptapi",
   "language": "python",
   "name": "kernel_chatgptapi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
